\begin{remark}
\label{rem:R-modules-convension}
For the remainder of the chapter, if \(M\) is said to be an \(R\)-module, then
\(M\) can be \emph{either a left or right \(R\)-module}---and \(R\) need
\emph{not be commutative}---we use this to \emph{generalize} propositions for
\emph{both} left and right modules simultaneously, whenever possible. On the
other hand, if we \emph{specify} the side of the multiplicative structure of
\(M\), then it may well be the case that the proposition does \emph{only work}
for this strict case \emph{or} that the \emph{distiction} between right and left
modules is \emph{important} in some way.
\end{remark}

\section{Free Modules}

\subsection{Construction}

As always, if \(S\) is a set and \(M\) is an \(R\)-module, for some ring \(R\),
we define \(M^{\oplus S}\) to be the collection of \emph{finitely supported
  set-functions} \(S \to M\). We define on \(M^{\oplus S}\) an \(R\)-module
structure as follows: for every \(\alpha \in M^{\oplus S}\) and \(r \in R\) we
define
\[
(r \alpha)(s) \coloneq r (\alpha(s)).
\]

If we consider the module of \(R\) over itself, we can define a set-function
\(\iota: S \to R^{\oplus S}\) by mapping \(s \mapsto \mathbf{s}\), where
\[
\mathbf{s}(x) \coloneq
\begin{cases}
  1, &\text{if } x = s, \\
  0, &\text{if } x \neq s.
\end{cases}
\]

For every set \(S\), we define a corresponding module module \(F_R S\) composed
of of formal sums \(\sum_{s \in S} a_s s\) such that \(a_s \in R\) is non-zero
only for finitely many \(s \in S\).

\begin{proposition}
\label{prop:free-module-structure-isomorphism}
There exists a natural isomorphism of \(R\)-modules \(F_R S \iso R^{\oplus S}\).
\end{proposition}

\begin{proof}
Let \(\Phi: F_R S \to R^{\oplus S}\) be a map given by
\(\sum_{s \in S} a_s s \mapsto \sum_{s \in S} a_s \mathbf{s}\). Clearly, such
map is injective and preserves both multiplicative and additive structures, thus
\(\Phi\) is an \(R\)-module morphism. Moreover, if \(\alpha \in R^{\oplus S}\)
is any function, since \(\alpha\) has finite support, the formal sum
\(\sum_{s \in S} \alpha(s) s\) is a well defined element of \(F_R S\). Also,
mapping this element under \(\Phi\) yields
\(\sum_{s \in S} \alpha(s) \mathbf{s}\) and, for every \(x \in S\), we have
\(\sum_{s \in S} \alpha(s) \mathbf{s}(x) = \alpha(s) \mathbf{x}(x) =
\alpha(x)\). Therefore the map is surjective, hence an isomorphism.
\end{proof}

\begin{proof}
Let \(A\) and \(B\) be two sets such that \(F_R A = F_R B\). In particular, it
follows that for all \(a \in A\), there exists an element \(a = \sum_{j=1}^n r_j
b_j \in F_R B\), moreover, each \(b_i \in B\) can be written as \(\sum_{j=1}^m
r_j(b_i) a_j\)
\end{proof}

\begin{proposition}[Free module universal property]
\label{prop:free-mod-univ-prop}
Let \(R\) be a ring and \(S\) be any set. Given any \(R\)-module \(M\) and a
\emph{set-function} \(f: S \to M\), there exists a \emph{unique \(R\)-module
  morphism} \(\phi: F_R S \to M\) such that the following diagram commutes in
\(\Set\)\footnote{It is to be noted the subtlety of not adding a dashed arrow
  (denoting uniqueness) for \(\phi\) in the diagram---this is done purposefully
  since the diagram is commutative in the category of sets, so there may well be
  a distinct \emph{set-function} \(F_R S \to M\) also making the diagram commute
  in \(\Set\).}:
\[
\begin{tikzcd}
F_R S \ar[r, "\phi"] &M \\
S \ar[u, "\iota"] \ar[ru, "f"', bend right] &
\end{tikzcd}
\]
where \(\iota: S \to F_R S\) is the mapping \(s \mapsto s\).
\end{proposition}

\begin{proof}
Let \(\phi: F_R S \to M\) be such that
\(\phi(\sum_{s \in S} a_s s) \mapsto \sum_{s \in S} a_s f(s)\) for any
\(\sum_{s \in S} a_s s \in F_R S\) so that clearly \(\phi \iota = f\) since
\(\phi \iota(s) = \phi(s) = f(s)\). Moreover, for any two
\(\sum_{s \in S} a_s s, \sum_{s \in S} b_s s \in F_R S\) we have
\begin{align*}
\phi\bigg( \sum_{s \in S} a_s s + \sum_{s \in S} b_s s \bigg)
&= \phi\bigg( \sum_{s \in S} (a_s + b_s) s \bigg)
= \sum_{s \in S} (a_s + b_s) f(s)
= \sum_{s \in S} a_s f(s) + \sum_{s \in S} b_s f(s) \\
&= \phi\bigg( \sum_{s \in S} a_s s \bigg)
+ \phi\bigg( \sum_{s \in S} b_s s \bigg).
\end{align*}
Furthermore, \(\phi\) certainly preserves the multiplicative structure by \(R\)
elements. Therefore \(\phi\) is an \(R\)-module morphism. Since \(f\) completely
determines the image of \(\phi\), it is the unique morphism such that
\(\phi \iota = f\).
\end{proof}

\begin{corollary}
\label{cor:set-to-module-injective}
The mapping \(\iota: S \emb F_R S\) given by \(s \mapsto s\) is injective.
\end{corollary}

\begin{proof}
For any pair \(s, s' \in S\) of distinct elements, consider the module
\(M \coloneq F_R \{s, s'\}\) and a set-function \(f: S \to M\) with \(f(s) = s\)
and \(f(s') = s'\). Then, by the universal of free modules, there exists a
unique morphism of \(R\)-modules \(\phi: F_R S \to M\) such that \(\phi \iota =
f\). If \(\iota(s)\) was equal to \(\iota(s')\), then \(f(s)\) \(f(s')\), which
cannot be the case---thus \(\iota(s) \neq \iota(s')\) for all \(s, s' \in S\)
distinct, hence \(\iota\) is injective.
\end{proof}

\begin{proposition}
\label{prop:ring-poly-is-free-commutative-R-algebra}
Let \(A \coloneq \{1, \dots, n\}\) be a set of \(n\) elements and define a map
\(\iota: A \to R[x_1, \dots, x_n]\) by \(j \mapsto x_j\). Then \(R[x_1, \dots,
x_n]\) is a \emph{free commutative \(R\)-algebra on \(A\)}.
\end{proposition}

\begin{proof}
We prove that \(R[x_1, \dots, x_n]\) satisfies the universal property for
\(A\). Let \(\alpha: R \to M\) be any \(R\)-algebra and \(f: A \to M\) be a
set-function. From \cref{prop:universal-property-polynomial-rings} we find a
unique extension \(\overline{\alpha}: R[x_1, \dots, x_n] \to S\) such that
\(\overline{\alpha}|_R = \alpha\) and \(\overline{\alpha}(x_j) \coloneq
f(j)\). Therefore, \(\overline{\alpha}\) is the uniquely determined
\(R\)-algebra morphism such that \(\overline{\alpha} \iota = f\).
\end{proof}

\subsection{Free Modules from Subsets}

Given any \(R\)-module \(M\) and a subset \(S \subseteq M\) of its elements, one
can define a free module \(R^{\oplus S}\) out of \(S\) and, from the universal
property of free modules, there exist a unique \(R\)-map \(\phi: R^{\oplus S}
\to M\) such that \(\phi \iota = i\), where \(\iota: S \emb R^{\oplus S}\) and
\(i: S \emb M\) is the canonical inclusion.

It is to be noted that the image \(\phi(R^{\oplus S}) \subseteq M\) is a
submodule of \(M\) and its elements are of the form \(\sum_{s \in S} a_s s\) for
\(a_s \in R\) non-zero only for finitely many \(s \in S\). We'll denote the
submodule \emph{generated} by \(S\) on \(M\) by the notation
\(\langle S \rangle\).


\begin{definition}[Finitely generated module]
\label{def:finitely-generated-module}
An \(R\)-module \(M\) is said to be \emph{finitely generated} exactly when there
exists a \emph{finite subset} \(S \subseteq M\) such that
\(M = \langle S \rangle\). Equivalently, \(M\) is finitely generated if there
exists a \emph{surjective} \(R\)-map \(R^{\oplus n} \epi M\) for a positive
integer \(n \in \Z_{>0}\).
\end{definition}

\begin{remark}[Submodules]
\label{rem:submodules-finitely-generated}
The reader should be cautious when working with finitely generated modules, for
instance, \emph{it is not true} that a finitely generated module has finitely
generated modules.

For instance, if we consider the ring of polynomials
\(P \coloneq \Z[x_1, x_2, \dots]\) on infinitely many variables, then
\(P = \langle 1 \rangle\) is finitely generated \emph{as a
  \(P\)-module}. However, if we consider the ideal
\(\ideal{a} \coloneq (x_1, x_2, \dots) \subseteq P\), one cannot take a finite
collection of polynomials of \(P\) and generate all of \(\ideal{a}\). Indeed, if
\(S \subseteq P\) is any finite collection, since polynomials have finitely many
terms, there must exist, for all \(p(x_1, x_2, \dots) \in S\), a maximum index
\(j \in \Z_{>0}\) such that \(x_j\) appears as a variable in \(p\) with a
non-zero coefficient. Taking the maximum index over all polynomials of \(S\), we
are still left with only a finite index, say \(n \in \Z_{>0}\), such that
\(x_n\) is the highest-index variable appearing any of the polynomials of
\(S\)---hence \(x_{n+1}\) is not contemplated by any of the polynomials of
\(S\), therefore this set cannot generate \(\ideal{a}\).
\end{remark}

\begin{definition}[Noetherian module]
\label{def:noetherian-module}
An \(R\)-module \(M\) is said to be a \emph{Noetherian module} if every
submodule of \(M\) is \emph{finitely generated as an \(R\)-module}.
\end{definition}

We can state the definition for \emph{Noetherian rings} (see
\cref{def:noetherian-ring}) equivalently as follows: a ring \(R\) is said to be
a Noetherian if \(R\) is a Noetherian \(R\)-module.

\begin{lemma}
\label{lem:finitely-generated-from-submodule}
Let \(M\) be an \(R\)-module, and \(N \subseteq M\) be a submodule. Then if both
\(N\) and \(M/N\) are finitely generated, then \(M\) is finitely generated.
\end{lemma}

\begin{proof}
Let \(N = \langle A \rangle\) and \(M/N = \langle B \rangle\) for finite sets
\(A \subseteq N\) and \(B \subseteq M/N\). If \(m \in M\) is any element, then
the class \(m + N \in M/N\) can be written as
\(m + N = \sum_{b \in B} r_b b + N\) for \(r_b \in R\). Moreover, since
\(m - \sum_{b \in B} r_b b \in N\), we can write
\(m - \sum_{b \in B} r_b b = \sum_{a \in A} r_a a\) for \(r_a \in R\). Therefore
\[
m = \sum_{a \in A} r_a a + \sum_{b \in B} r_b b.
\]
This shows that \(A \cup B\) generates \(M\), thus \(M\) is finitely generated.
\end{proof}

\begin{proposition}
\label{prop:noetherian-from-submodule}
Let \(M\) be an \(R\)-module, and \(N \subseteq M\) be a submodule. Then \(M\)
is Noetherian if and only if \emph{both} \(N\) and \(M/N\) are Noetherian.
\end{proposition}

\begin{proof}
Analogous to the proof of \cref{prop:image-of-noetherian-is-noetherian}, if
\(M\) is a Noetherian module, then the natural projection \(\pi: M \epi M/N\)
shows that \(M/N\) is Noetherian. Since \(N\) is a submodule of \(M\), then
\(N\) is finitely generated and every submodule \(P \subseteq N\) is also a
submodule of \(M\), thus \(P\) must be finitely generated.

For the converse, suppose both \(M/N\) and \(N\) are Noetherian. Fix any
submodule \(P \subseteq M\). Consider the submodule \(P \cap N\) of both \(P\)
and \(N\)---from the hypothesis that \(N\) is Noetherian, \(P \cap N\) is
finitely generated. By \cref{prop:second-iso-R-mod} we find that there exists a
canonical isomorphism \(P/(P \cap N) \iso (N + P)/N\). Since
\((N + P)/N\) is a submodule of \(M/N\), by the hypothesis that \(M/N\) is
Noetherian it follows that \(P/(P \cap N)\) is finitely generated. From
\cref{lem:finitely-generated-from-submodule} we find that \(P\) itself is
finitely generated, making \(M\) Noetherian.
\end{proof}

\begin{corollary}
\label{cor:noetherian-ring-fg-module-is-noetherian}
Given a \emph{Noetherian ring} \(R\), any \emph{finitely generated} \(R\)-module
\(M\) is \emph{Noetherian}.
\end{corollary}

\begin{proof}
Since \(M\) is finitely generated, there exists a surjective \(R\)-module
morphism \(p: R^{\oplus n} \epi M\), for some \(n \in \Z_{> 0}\)---therefore
\(M \iso R^{\oplus n}/{\ker p}\). Now, if \(R^{\oplus n}\) is Noetherian, by
\cref{prop:noetherian-from-submodule}, then \(\ker p\) and \(R^{\oplus n}/{\ker
  p}\) are both Noetherian, and therefore \(M\) is Noetherian.

We prove that \(R^{\oplus n}\) is Noetherian by induction on \(n\). For
\(n = 1\) we have that \(R^{\oplus 1} \iso R\) is Noetherian. Assume that
\(R^{\oplus(n - 1)}\) is Noetherian for some \(n > 1\). Notice that the
inclusion \(\iota: R^{\oplus (n-1)} \emb R^{\oplus n}\) mapping
\((r_1, \dots, r_{n-1}) \mapsto (r_1, \dots, r_{n-1}, 0)\) is an \(R\)-map and
makes \(R^{\oplus (n-1)}\) into a submodule of \(R^{\oplus n}\). Considering the
canonical projection of the \(n\)-th coordinate \(\pi_n: R^{\oplus n} \epi R\),
we have \(\ker \pi_n = R^{\oplus (n - 1)}\). By the first isomorphism theorem we
obtain an isomorphism
\[
R^{\oplus n}/R^{\oplus (n-1)} \iso R,
\]
therefore \(R^{\oplus n}/R^{\oplus (n-1)}\) is Noetherian. Applying
\cref{prop:noetherian-from-submodule} we find that \(R^{\oplus n}\) is
Noetherian---thus \(M\) is Noetherian.
\end{proof}

\subsection{Finite Generation of \texorpdfstring{\(R\)}{R}-Algebras}

\begin{definition}
\label{def:finite-generation-algebras}
Let \(A\) be an \(R\)-algebra. We define the following two distinct concepts
regarding the finiteness of the generation of \(A\):
\begin{itemize}[(a)]\setlength\itemsep{0em}
\item The \(R\)-algebra \(A\) is said to be \emph{finite} if there exists a
  \emph{surjective \(R\)-module morphism}
  \[
  \phi: R^{\oplus n} \epi A
  \]
  for some \(n \in \Z_{>0}\), so that
  \[
  A \iso R^{\oplus n}/{\ker \phi},
  \]
  where \(\ker \phi\) is a \emph{submodule} of \(R^{\oplus n}\). In other words,
  \(A\) is finitely generated as a \emph{module over \(R\)}. This nomenclature
  is unfortunately misleading: even though we say that \(A\) is finite, \(A\) may
  well be an \emph{infinite set}.

\item The \(R\)-algebra \(A\) is said to be of \emph{finite type} if there
  exists a \emph{surjective \(R\)-algebra morphism}
  \[
  \alpha: R[x_1, \dots, x_n] \epi A
  \]
  for some \(n \in \Z_{>0}\), so that
  \[
  A \iso R[x_1, \dots, x_n]/{\ker \alpha},
  \]
  where \(\ker \alpha\) is an \emph{ideal} of the ring \(R[x_1, \dots,
  x_n]\). In other words, \(A\) is finitely generated as an \emph{algebra over
    \(R\)}.
\end{itemize}
\end{definition}

\begin{remark}[Finite type but not finite]
\label{rem:finite-type-not-finite}
Let \(A\) be an \(R\)-algebra. If \(A\) is finite, then \(A\) is also of finite
type. On the other hand, if we consider the \(R\)-algebra \(R[x]\), we find that
\(R[x]\) is clearly of finite type, but there exists no surjective \(R\)-map
from \(R^{\oplus n}\) to \(R[x]\), therefore \(R[x]\) isn't finite.
\end{remark}

\section{Linear Independence \& Bases}

\subsection{Linear Independence}

\begin{definition}[Linear independence]
\label{def:linear-independent-R-mod}
Let \(J\) be a set and \(M\) be an \(R\)-module. An indexed set \(j: J \to M\)
is said to be \emph{linearly independent} if the unique \(R\)-module morphism
\(\phi: F_R J \to M\), making the diagram
\[
\begin{tikzcd}
F_R J \ar[r, dashed, "\phi"] &M \\
J \ar[u, hook, "\iota"] \ar[ru, bend right, "j"']
\end{tikzcd}
\]
commute in \(\Set\), is \emph{injective}. The indexed set \(j\) is said to
\emph{generate} \(M\) if \(\phi\) is \emph{surjective}. Finally, if \(\phi\) is
an \emph{isomorphism}, then \(j\) is a \emph{basis} of \(M\)---in this case,
since \(F_R J \iso R^{\oplus J}\), then \(R^{\oplus J} \iso M\).
\end{definition}

\begin{corollary}
\label{cor:free-iff-basis}
An \(R\)-module is \emph{free} if and only if it admits a \emph{basis}.
\end{corollary}

\begin{proof}
If \(M\) is free, then there exists a set \(S\) such that \(M \iso F_R S\), then
\(S\) is a basis for \(M\). For the converse, if \(M\) admits a basis \(S\),
then \(F_R S \iso M\).
\end{proof}

As with vector spaces we'll intentionally identify an indexed set \(j: J \to M\)
simply by \(J\) itself and say that \(J\) is a \emph{subset} of \(M\). The good
old abuse of notation.

\begin{remark}[Singletons]
\label{rem:singletons-arent-LI}
Singletons do \emph{not} need to be linearly independent. A simple example is
\(\{3\} \subseteq \Z/9\Z\).
\end{remark}

The following lemma regarding maximality of linearly independent sets is
equivalent to the Axiom of Choice.

\begin{lemma}[Maximality]
\label{lem:maximal-LI-subset}
Let \(M\) be an \(R\)-module and \(S \subseteq M\) be a linearly independent
set. There exists a \emph{maximal linearly independent} subset of \(M\)
containing \(S\).
\end{lemma}

\begin{proof}
Let \(\mathcal{S}\) be the non-empty collection of linearly independent sets of
\(M\) containing \(S\). Notice that a the union of a chain of elements of
\(\mathcal{S}\) is again a linearly independent set containing \(S\)---thus
\(\mathcal{S}\) is closed under arbitrary unions. In other words, every chain of
elements has an upper bound in \(\mathcal{S}\). By Zorn's lemma, it follows that
the collection \(\mathcal{S}\) has a maximal element.
\end{proof}

\begin{remark}[Maximality, generation, and bases]
\label{rem:maximality-not-generation}
It should be noted right away that being a maximal linear independent set does
\emph{not} imply that the set generated the module. For instance,
\(\{2\} \subseteq \Z\) is a maximal linearly independent subset of \(\Z\)
containing \(\{2\}\), but obviously it doesn't generate \(\Z\). This, however is
true for the case of vector spaces.

On the other hand, every base of a module is necessarily a maximal linearly
independent set.
\end{remark}

\begin{definition}[Invariant basis number]
\label{def:IBN}
A ring \(R\) is said to satisfy the \emph{invariant basis number} (IBN) property
if \(R^m \iso R^n\) as \(R\)-modules if and only if \(m = n\).
\end{definition}

\begin{corollary}
\label{cor:IBN-matrix-criterion}
A ring \(R\) does \emph{not} satisfy the invariant basis number property if and
only if there exists distinct natural numbers \(n, m \in \N\), and matrices \(A
\in M_{m \times n}(R)\) and \(B \in M_{n \times m}(R)\) such that
\[
A B = \Id_m\quad \text{ and }\quad B A = \Id_n.
\]
\end{corollary}

\begin{corollary}
\label{cor:fields-are-IBN}
Every field satisfies the invariant basis number property.
\end{corollary}

\begin{proposition}
\label{prop:IBN-morphism-criterion}
Let \(f: R \to S\) be a ring morphism, for \emph{any} two rings \(R\) and
\(S\). If \(S\) satisfies the invariant basis number property, then so does
\(R\).
\end{proposition}

\begin{proof}
Let \(A \coloneq [a_{ij}] \in M_{m \times n}(R)\) and
\(B \coloneq [b_{ij}] \in M_{n \times m}(R)\) be matrices and define both
\(fA \coloneq [f(a_{ij})] \in M_{m \times n}(S)\) and
\(fB \coloneq [f(b_{ij})] \in M_{n \times n}(S)\). Notice that since \(f\) is a
ring morphism we have \((f A)(f B) = f(A B)\). Since we cannot have \((f A) (f
B)\) and \((f B) (f A)\) equal to their respective identities, it follows that
\(A B\) and \(B A\) are also not equal to the identity matrices---therefore
\(R\) is satisfies the IBN property.
\end{proof}

\begin{theorem}
\label{thm:commutative-rings-satisfy-IBN}
All commutative rings satisfy the invariant basis number property.
\end{theorem}

\begin{proof}
Let \(R\) be a commutative ring. By
\cref{prop:commutative-rings-have-maximal-ideals} we find that \(R\) contains a
proper maximal ideal \(\ideal{m}\)---therefore the quotient ring \(R/\ideal{m}\)
is a field. Considering the canonical projection \(R \epi R/\ideal{m}\), we
obtain, by \cref{prop:IBN-morphism-criterion}, that \(R\) is IBN since fields
are IBN
\end{proof}

\begin{example}
\label{exp:End(V)-isnt-IBN}
Let \(V\) be an \emph{infinite dimensional} \(k\)-vector space, for some field
\(k\). The ring \(R \coloneq \End_{\Vect_k}(V)\) of endomorphisms of \(V\) does
\emph{not} satisfy the IBN property.

First we prove that \(\End_{\Vect_k}(V \oplus V) \iso R^4\). Notice that any
\(k\)-linear map \(f: V \oplus V \to V \oplus V\) can be decomposed into its
projections \(f_1, f_2: V \oplus V \to V\). Further, each projection \(f_j\) can
be again decomposed into unique \(k\)-linear morphisms \(p_j, q_j: V \to V\)
such that \(f_j = p_j + q_j\)---for \(j \in \{1, 2\}\). Therefore, the map \(f\)
is uniquely determined by the quadruple \((p_1, q_1, p_2, q_2)\), where \(f =
(p_1 + q_1, p_2 + q_2)\). Hence we may map bijectively \(\End_{\Vect_k}(V \oplus
V) \to R^4\) via \(f \mapsto (p_1, q_1, p_2, q_2)\).

Notice that, since \(V\) is infinite dimensional, we have
\(\dim_k V = \dim_k(V \oplus V)\)---thus \(V \iso V \oplus V\), and hence
\(\End_{\Vect_k}(V \oplus V) \iso \End_{\Vect_k}(V)\) (see
\cref{prop:M-iso-N-then-iso-between-End}). Notice that from our earlier result,
we just concluded that \(R \iso R^4\), which proves that \(R\) does not satisfy
the IBN property.
\end{example}

\begin{example}
\label{exp:End(Zinfty)-not-IBM}
Let \(M \coloneq \prod_{j \in \N} \Z\) be a \(\Z\)-module and a ring
\(R \coloneq \End_{\Mod{Z}}(M)\). We'll show that \(R\) does not satisfy the IBN
property.

Define parallel \(\Z\)-module morphisms \(\phi, \psi: M \para M\) given by
\begin{align*}
  \phi(a_1, a_2, \dots) &\coloneq (a_1, a_3, a_5,\dots), \\
  \psi(a_1, a_2, \dots) &\coloneq (a_2, a_4, a_6,\dots).
\end{align*}
Then, if \(f \in R\) is any endomorphism, let \(f_j: M \to \Z\) be its \(j\)-th
projection. Define endomorphisms \(g, h: M \para M\), whose projections are
given by
\begin{align*}
&g_{2j - 1} \coloneq f_j\ \text{for \emph{odd}}\
j \in \Z_{> 0}\ \text{and \emph{zero} for the remaining projections,} \\
&h_{2j} \coloneq f_j\ \text{for \emph{even}}\
j \in \Z_{> 0}\ \text{and \emph{zero} for the remaining projections.}
\end{align*}

Then we obtain the equality
\begin{align*}
\phi g + \psi h
&= (g_1, g_3, g_5, \dots) + (h_2, h_4, h_6, \dots) \\
&= (f_1, 0, f_3, 0, f_5, \dots)
+ (0, f_2, 0, f_4, 0 f_6, \dots) \\
&= f
\end{align*}
which is uniquely defined for \(f\)---hence \(\{\phi, \psi\}\) is a basis for
the \emph{right}-\(R\)-module \(R\) (over itself). From this we conclude that
\(R \iso R^2\) by mapping \(f \mapsto (g, h)\) and with an inverse
\((g, h) \mapsto \phi g + \psi h = f\). This shows that \(R\) does not satisfy
the invariant basis number property.
\end{example}

\subsection{Free Modules Basis}

\begin{lemma}
\label{lem:LI-in-free-iff-LI-in-free-over-field-of-fractions}
Let \(R\) be an integral domain, and \(M \coloneq R^{\oplus A}\) be a free
\(R\)-module. Considering the inclusion \(M \emb \Frac(R)^{\oplus A}\), a subset
\(S \subseteq M\) is linearly independent in \(M\) if and only if it is linearly
independent in \(\Frac(R)^{\oplus A}\).
\end{lemma}

\begin{proof}
We do the proof of both statements via the contrapositive. Define the notation
\(V \coloneq \Frac(R)^{\oplus A}\). Suppose \(S\) is linearly independent in
\(V\), then there exists a collection of elements \((a_s/b_s)_{s \in S}\) for
\(a_s/b_s \in \Frac(R)\) non-zero only for finitely many \(s \in S\)---but not
all zero---such that
\begin{equation}\label{eq:LD-in-Frac(R)-V}
\sum_{s \in S} \frac{a_s}{b_s} \cdot s = 0
\end{equation}
Consider the \emph{finite} set \(S' \coloneq \{s \in S \colon a_s \neq
0\}\). Since \(b_s \neq 0\) for all \(s \in S'\), one can consider the
\emph{non-zero} finite product \(b \coloneq \prod_{s \in S'} b_s\). Notice that,
for all \(s_0 \in S\) we have
\[
b \cdot \frac{a_{s_0}}{b_{s_0}}
= \bigg(\prod_{s \in S \setminus \{s_0\}} b_s \bigg) a_{s_0},
\]
which is simply an element of \(R\) since the denominator of the fraction is
\(1\). We then define a collection \((c_s)_{s \in S}\) as
\(c_{s'} \coloneq \prod_{s \in S \setminus \{s'\}} b_s\) for all \(s' \in S'\),
and \(c_s \coloneq 1\) for all \(s \in S \setminus S'\). Notice that
\cref{eq:LD-in-Frac(R)-V} is equivalent to
\begin{equation}\label{eq:LD-in-M}
\sum_{s \in S} (c_s a_s) s = 0,
\end{equation}
with coefficients \(c_s a_s \in R\) for which finitely many are non-zero---but
not all are zero---therefore \cref{eq:LD-in-M} lies in \(M\). From this we
conclude that \(S\) is linearly dependent on \(M\).

For the converse, suppose that \(S\) is linearly dependent on \(M\), then there
exists a collection \((r_s)_{s \in S}\)---of elements \(r_s \in R\) that are
non-zero for only finitely many \(s \in S\), and not all zero---such that
\begin{equation}\label{eq:LD-in-both-M-and-V}
\sum_{s \in S} r_s s = 0.
\end{equation}
From the inclusion \(R \emb \Frac(R)\), we see that \(r_s \in \Frac(R)\) for all
\(s \in S\), and therefore \cref{eq:LD-in-both-M-and-V} lies in both \(M\) and
\(V\)---which proves that \(S\) is also linearly dependent in \(V\).
\end{proof}

\begin{proposition}
\label{prop:LI-leq-maximal-LI}
Let \(R\) be an integral domain, and \(M\) be a \emph{free} \(R\)-module. If
\(B\) is a maximal linearly independent subset of \(M\), and \(S\) is a linearly
independent subset of \(M\), then
\[
|S| \leq |B|.
\]
Moreover, if \(C\) is another maximal linearly independent subset of \(M\),
then
\[
|C| = |B|.
\]
\end{proposition}

\begin{proof}
By \cref{lem:LI-in-free-iff-LI-in-free-over-field-of-fractions} it is equivalent
to prove the proposition for a field \(R = k\) and a \(k\)-vector space
\(M = V\).

We construct a map \(\iota: S \to B\) inductively. Assume a well-ordering on the
set \(S\). We use transfinite induction---that is, assume \(\iota\) is defined,
injectively, for all \(w < v\) for some \(v \in S\), and define \(B'\) to
consist of the elements of \(B\) but for all \(w < v\) we replace
\(\iota(w) \in B\) by \(w\). Our inductive hypothesis will be that \(B'\) is
still a maximal linearly independent set of \(V\).

We now define \(\iota(v)\). Since by hypothesis the set \(B'\) is maximal, then
\(B' \cup \{v\}\) must be linearly dependent, so that there exists a collection
\((a_{j})_{j=0}^n\) of elements \(a_j \in k\), not all zero, such that
\begin{equation}\label{eq:B'-maximal-and-stuff}
a_0 v + a_1 b_1 + \dots + a_n b_n = 0
\end{equation}
for some finite subset \((b_j)_{j=1}^n \subseteq B'\). Since \(B'\) is linearly
independent, it must be the case that \(a_0 \neq 0\). Moreover, since \(S\) is
also linearly independent, it follows that not all \(b_j\) can be members of
\(S\). With a possible change of indexing, we may thus assume that
\(a_1 \neq 0\) and \(b_1 \in B' \setminus S\)---this implies that
\(b_1 \neq j(w)\) for all \(w < v\), hence we may set \(\iota(v) \coloneq b_1\)
and not loose injectivity of \(\iota\).

Consider now the set \(B''\), whose elements are those of \(B'\) but with
\(b_1 = \iota(v)\) replaced by \(v\). Since \(B'\) is linearly independent, then
\(B'' \setminus v\) is linearly independent therefore, by
\cref{eq:B'-maximal-and-stuff} we find \(v = -\sum_{j=1}^n \frac{a_j}{a_0}
b_j\), hence no subset of \(B''\)---containing or not \(v\)---can be linearly
dependent, since that would imply the linear dependence of \(B'\). We conclude
that \(B''\) is linearly independent and maximal, which finishes the transfinite
induction and proves that the injective set-function \(\iota: S \mono B\) can be
constructed. This shows that \(|S| \leq |B|\). For the equality, we can simply
do the construction of injective maps \(C \mono B\) and \(B \mono C\) and
conclude that \(|C| = |B|\).
\end{proof}

\begin{corollary}
\label{cor:integral-domain-satisfies-IBN}
Let \(R\) be an integral domain, and \(A\) and \(B\) be sets. Then there exists
an isomorphism of \(R\)-modules \(F_R A \iso F_R B\) if and only if there exists
a bijection \(A \iso B\).
\end{corollary}

\begin{proof}
If \(F_R A \iso F_R B\), then \(A\) and \(B\) are maximal linearly independent
sets of the ``same'' module, which by \cref{prop:LI-leq-maximal-LI} implies in
\(|A| = |B|\).

If \(|A| = |B|\), let \(f: A \isoto B\) be a bijective set function, and
consider the canonical inclusions \(i_A: A \emb F_R A\) and
\(i_B: B \emb F_R B\). Consider the indexed sets
\(j_A \coloneq i_B f: A \to F_R B\) and
\(j_B \coloneq i_A f^{-1}: B \to F_R A\)---both of which are injective, since
are a composition of an injection with a bijection. The are unique induced
\(R\)-module morphisms \(\phi: F_R A \to F_R B\) and \(\psi: F_R B \to F_R A\)
are, by construction, such that \(\phi i_A = j_A\) and \(\psi i_B =
j_B\). Consider the following commutative diagram in \(\Set\):
\[
\begin{tikzcd}
F_R A \ar[r, dashed, "\phi"]
&F_R B \ar[r, dashed, "\psi"]
&F_R A \ar[r, dashed, "\phi"]
&F_R B
\\
A \ar[u, hook, "i_A"] \ar[r, "f"']
&B \ar[u, hook, "i_B"] \ar[r, "f^{-1}"']
&A \ar[u, hook, "i_A"] \ar[r, "f"']
&B \ar[u, hook, "i_B"]
\end{tikzcd}
\]
Using the universal property on the first two squares we find that \(\psi \phi\)
is the unique \(R\)-module morphism induced by \(i_A\)---but since
\(\Id_{F_R A}\) also satisfies the property, it follows that
\(\psi \phi = \Id_{F_R A}\). Analogously, applying the universal property on the
last two squares we obtain \(\phi \psi = \Id_{F_R B}\). Therefore \(\phi\) and
\(\psi\) are inverses of each other and \(F_R A \iso F_R B\).
\end{proof}

\begin{lemma}
\label{lem:basis-free-to-basis-vector-space}
Let \(R\) be a commutative ring, and \(F\) be a free \(R\)-module with a basis
\(B\). If \(\ideal{m} \subseteq R\) is a maximal ideal, the collection
\((b + \ideal m F)_{b \in B}\) forms a basis of the vector space
\(F/(\ideal m F)\) over the field \(R/\ideal{m}\)\footnote{Let \(R\) be a
  commutative ring. If \(\ideal a \subseteq R\) is an ideal, and \(M\) is an
  \(R\)-module, we there exists a natural structure of \((R/{\ideal a})\)-module
  that can be endowed on the abelian group \(M/(\ideal a M)\) via the
  multiplication
  \[
  (r + \ideal a) \cdot (m + \ideal a M) \coloneq r m + \ideal a M.
  \]
}.
\end{lemma}

\begin{proof}
We shall prove that \(B/(\ideal{m} F) \coloneq (b + \ideal m F)_{b \in B}\)
forms a minimal generating set of \(F/(\ideal m F)\)---so that by
\cref{lem:minimal-generating-is-basis} we obtain that \(B/(\ideal m F)\) is a
basis. If \(x + \ideal m F \in F/(\ideal m F)\) is any element, consider a
representative \(x \in F\) and let \((x_b)_{b \in B}\) be a collection of
elements \(x_b \in R\)---which are non-zero only for finitely many
\(b \in B\)---such that \(x = \sum_{b \in B} x_b b\). Taking the natural
projection \(F \epi F/(\ideal m F)\) of \emph{sets}, we find that
\(x + \ideal m F = \big( \sum_{b \in B} x_b b \big) + \ideal m F\). By the
\((R/\ideal m)\)-module structure of \(F/(\ideal m F)\), we find that
\[
x + \ideal m F
= \bigg( \sum_{b \in B} x_b b \bigg) + \ideal m F
= \sum_{b \in B} x_b b + \ideal m F
= \sum_{b \in B} (x_b + \ideal m) (b + \ideal m F).
\]
From construction, the collection \((x_b + \ideal m)_{b \in B}\) is composed of
finitely many non-zero elements \(x_b + \ideal m \in R/\ideal{m}\). From this we
conclude that \(B/(\ideal m F)\) is indeed a generating set for
\(F/(\ideal m F)\).

\todo[inline]{How can I finish this proof? One can prove the linear independence
or minimality of \(B/(\ideal m F)\), but what is the easiest way out?}
\end{proof}

\begin{proposition}
\label{prop:comm-ring-basis-have-same-cardinality}
Let \(R\) be a non-zero commutative ring. If \(F\) is a free \(R\)-module and
both \(A\) and \(B\) are basis of \(F\), then \(|A| = |B|\).
\end{proposition}

\begin{proof}
From \cref{prop:commutative-rings-have-maximal-ideals} we know that \(R\) admits
a maximal ideal \(\ideal m \subseteq R\). We know from
\cref{lem:basis-free-to-basis-vector-space} that the collections \((a + \ideal m
F)_{a \in A}\) and \((b + \ideal m F)_{b \in B}\) are both basis for the
\((R/\ideal{m})\)-vector space \(F/(\ideal m F)\). Since basis of vector spaces
have the same cardinality, it follows that \(|A| = |B|\).
\end{proof}

\begin{definition}[Rank]
\label{def:rank-of-module}
Let \(R\) be an integral domain. We define the \emph{rank} of a free
\(R\)-module \(M\) to be the cardinality of a maximal linearly independent
subset of \(M\)---this cardinal shall be denoted \(\rank_R M\). If \(R = k\) is a
field, then \(M\) is a \(k\)-vector space and thus \(\rank_k M = \dim_k M\).
\end{definition}

\begin{proposition}
\label{prop:generating-set-contains-maximal-LI}
Let \(R\) be an integral domain and \(M\) be an \(R\)-module. If \(M\) is
generated by a subset \(S \subseteq M\), then \(S\) \emph{contains} a maximal
linearly independent subset of \(M\)---hence \(|S| \geq \rank_R M\).
\end{proposition}

\begin{proof}
By \cref{lem:LI-in-free-iff-LI-in-free-over-field-of-fractions}, we can treat
the case for the field \(k \coloneq \Frac(R)\) and a vector space
\(V \coloneq M\). Consider the power set \(2^S\) of subsets of \(S\), ordered by
inclusion---in particular, let \(\mathcal{S} \subseteq 2^S\) contain all
linearly independent subsets of \(S\). By Zorn's lemma, there exists a maximal
linearly independent set \(B \in \mathcal{S}\) of \(2^S\). Since maximal
linearly independent sets form a basis (mind you, this is true only for vector
spaces), then in particular \(S\) is contained in the span of \(B\)---therefore
\(B\) is a maximal linearly independent set generating \(V\), that is, \(B\) is
a basis for \(V\).
\end{proof}

\begin{theorem}[Every module is the quotient of a free module]
\label{thm:any-module-is-quotient-of-free-module}
Given a ring \(R\), every right-\(R\)-module \(M\) (or left-\(R\)-module) is a
\emph{quotient} of a \emph{free} right-\(R\)-module \(F\) (or
left-\(R\)-module). Moreover, \(M\) is finitely generated if and only if one can
choose a finitely generated free module \(F\).
\end{theorem}

\begin{proof}
Define a free right-\(R\)-module \(F \coloneq R^{\oplus |M|}\) and let
\((x_m)_{m \in M}\) be a basis of \(F\). By the universal property of
free modules, the indexing of the basis of \(F\) induces a unique morphism of
right-\(R\)-modules \(p: F \to M\) such that \(p(x_m) = m\) for all \(m \in
M\)---which by construction is surjective. From the first isomorphism theorem we
find that
\[
M \iso F/{\ker g},
\]
therefore \(M\) is indeed the quotient of a free module.

For the last proposition, if \(F\) can be chosen to be finitely generated, then
it is immediate that \(M\) is finitely generated. For the converse, suppose that
\(M\) is finitely generated and \(M = \langle m_1, \dots, m_n \rangle\). Define
the free \(R\)-module \(F \coloneq R^{\oplus n}\) with a basis
\(\{x_1, \dots, x_n\}\) and consider the \(R\)-map \(p: F \to M\) defined by
\(p(x_j) \coloneq m_j\) for each \(1 \leq j \leq n\). Since \(\langle p(x_1),
\dots, p(x_n) \rangle = \langle m_1, \dots, m_n \rangle\), then \(p\) is
surjective, therefore the statement holds true.
\end{proof}

\begin{corollary}
\label{cor:any-module-is-quotient-of-free-module}
For any \(R\)-module \(M\) there exists an exact sequence of \(R\)-modules
\[
\begin{tikzcd}
G \ar[r] &F \ar[r, two heads] &M \ar[r] &0
\end{tikzcd}
\]
for \emph{free} \(R\)-modules \(G\) and \(F\).
\end{corollary}

\subsection{Direct Sums \& Products of Free \texorpdfstring{\(R\)}{R}-Modules}

\begin{proposition}
\label{prop:direct-sum-mod-free}
Let \((M_j)_{j \in J}\) be a family of free \(R\)-modules. Then the direct sum
\(\bigoplus_{j \in J} M_j\) is free.
\end{proposition}

\begin{proof}
Let \((S_j)_{j \in J}\) be set of basis for each respective \(M_j\), and define
\(S \coloneq \bigcup_{j \in J} S_j\). Let \(N\) be any \(R\)-module and \(f: S
\to N\) a set-function. Since \(M_j\) is free for all \(j \in J\), there exists
a unique morphism \(\phi_j: M_j \to N\) such that the diagram
\[
\begin{tikzcd}
M_j \ar[r, "\phi_j"] &N \\
S_j \ar[u, hook] \ar[ru, "f|_{S_j}"', bend right]
\end{tikzcd}
\]
commutes in \(\Set\). From the universal property of coproduct, the collection
\((\phi_j)_{j \in J}\) defines a unique morphism \(\phi: \bigoplus_{j \in J} M_j
\to N\) such that the diagram
\[
\begin{tikzcd}
M_j \ar[d, hook] \ar[rd, bend left, "\phi_j"] & \\
\bigoplus_{j \in J} M_j \ar[r, dashed, "\phi"] &N
\end{tikzcd}
\]
commutes in \(\Mod{R}\) for all \(j \in J\). Therefore in particular
\[
\begin{tikzcd}
\bigoplus_{j \in J} M_j \ar[r, "\phi"] & N \\
S \ar[u, hook] \ar[ru, bend right, "f"'] &
\end{tikzcd}
\]
commutes in \(\Set\)---which implies that \(\bigoplus_{j \in J} M_j\) is free.
\end{proof}

\begin{remark}
\label{rem:M/N-not-free}
If \(M\) is a free \(R\)-module and \(N\) is a free submodule of \(M\), it
\emph{does not follow} that the quotient \(M/N\) is free. For instance, take \(M
\coloneq \Z\) and the free submodule \(N \coloneq 2 \Z\), then \(M/N\) is not
free since \(\{1\}\) is not linearly independent in \(\Z/2\Z\).
\end{remark}

\subsubsection{Interesting Examples}

\begin{example}
\label{exp:free-module-over-integral-domain}
Let \(R\) be an integral domain, and \(M\) be a free \(R\)-module. If
\(a \in R\) and \(m \in M\) are such that \(a m = 0\), than either \(a = 0\) or
\(m = 0\).

Let \(S\) be a basis for \(M\) and consider \(R\) as a module over itself. Let
\(f: S \mono R\) be any injective \emph{set-function}. Since \(\iota: S \emb M\)
is injective, then the unique \(R\)-module morphism \(\phi: M \to R\)---making
the diagram
\[
\begin{tikzcd}
M \ar[r, "\phi"] &R \\
S \ar[u, tail, "\iota"] \ar[ru, bend right, tail, "f"']
\end{tikzcd}
\]
commute in \(\Set\)---must be injective, therefore \(\ker \phi = 0\). Notice
that if \(a m = 0\) then since \(\phi(0) = 0\) we have
\(\phi(a m) = a \phi(m) = 0\) but since \(R\) is an integral domain, then either
\(a = 0\) or \(\phi(m) = 0\)---that is, \(m \in \ker \phi\), which implies in
\(m = 0\).
\end{example}

\begin{example}
\label{exp:finite-solution-v-equal-nx}
Let \(M\) be a free \(\Z\)-module, and \(v \in M\) a non-zero element. Then
there exists only finitely many \(n \in \Z\) such that the equation \(v = n x\)
has a solution \(x \in M\).

Let \(S\) be a basis for \(M\), and let \(v = \sum_{s \in S} a_s s\)---where
\(a_s \in \Z\) is non-zero for only finitely many \(s \in S\), but not all
zero. Let \(n \in \Z\) be an integer such that there exists a solution
\(x = \sum_{s \in S} b_s s \in M\) for \(v = n x\), then since \(S\) is a basis
it follows that
\[
\sum_{s \in S}(a_s - n b_s) s = 0
\]
implies in \(a_s = n b_s\) for all \(s \in S\). Hence \(n\) must be a divisor of
all \(a_s\)---thus be necessarily have \(n \leq \gcd(a_s)_{s \in S}\). Since the
greatest common divisor is finite, then \(n\) can only assume a finite number of
values for there to be a solution of \(v = n x\) in \(M\).
\end{example}

\begin{remark}
\label{rem:direct-product-not-free}
The direct product of a family of free modules \emph{need not be free}. To see
this, we construct the following example.

Let \(M \coloneq \prod_{j \in \N} \Z\), we'll show that \(M\) is not a free
\(\Z\)-module. Define the submodule \(N \coloneq \bigoplus_{j \in \N} \Z\) of
\(M\). Suppose, for the sake of \emph{contradiction}, that \(M\) admits a basis
\(B\).

Notice that since each element of \(N\) has only finitely many non-zero entries,
it follows that for each \(n \in \N\) the of elements with \(n\) non-zero
entries can be represented by a sequence of pairs \((a_j, i_j)_{j=1}^n\) with
\(a_j \in \Z\) and a corresponding index \(i_j \in \N\). Therefore, the number
of elements with \(n\) non-zero entries is given by the finite product of
countable sets \((\Z \times \N)^n\)---which is itself countable. Then the
number of elements of \(N\) is given by the countable union
\(\bigcup_{n \in \N} (\bigcup_{j \in \N} \Z^n)\), which is again countable.

Let \(B_0 \subseteq B\) be the collection of all basis elements that appear when
expanding the elements of \(N\) in terms of \(B\)---such collection is
necessarily countable since \(N\) itself is countable. The free module
\(N_0 \coloneq F_R B_0 \subseteq M\) will then contain \(N\). Since \(B_0\) is
countable and the elements of \(N_0\) are finite linear combinations of the
elements of \(B_0\), then \(N_0\) is countable.

Consider the module \(\overline{M} \coloneq M/N_0\), has a basis
\(B \setminus B_0\). From \cref{exp:finite-solution-v-equal-nx}, for every non-zero
element \(\overline{x} \in \overline{M}\) there exists only finitely many
\(n \in \N\) such that the equation \(\overline{x} = n m\) admits a solution
\(m \in \overline{M}\).

Consider the subset
\[
S \coloneq \{(b_{j})_{j \in \N} \in M \colon
b_j = (\pm j!) a_j\text{, with } a_j \in \Z\},
\]
which has cardinality of the continuum, \(2^{\aleph_0}\), hence \(S\) is
uncountable. Therefore there exists \(s \in S\) such that \(s \notin
N_0\). Notice however that, from the construction of \(S\), every \(n \in \N\) is
such that the equation \(s = n m\) has a solution \(m \in M\)---but since
\(s \notin N_{0}\), this also implies that \(s = n \overline{m}\) has a solution
\(\overline{m} \in M/N_0\) for all \(n \in \N\). This contradicts our last
paragraph since \(M/N_0\) is supposedly free! From this we conclude that
\(M/N_0\) must \emph{not} be free, and \(M\) should not admit a basis. Thus
\(M\) \emph{is not a free \(\Z\)-module}.
\end{remark}

\section{Exact Sequences \& Decompositions of Modules}

\subsection{Direct Summands}

\begin{definition}[Direct summand]
\label{def:direct-summand}
Let \(P\) be an \(R\)-module and \(M\) be a submodule of \(P\). We say that
\(M\) is a \emph{direct summand} of \(P\) if there exists a submodule \(N\) of
\(P\) satisfying \(M \cap N = \{0\}\), called a \emph{complement} of \(M\), for
which
\[
P = M \oplus N.
\]
\end{definition}

\begin{definition}[Retract]
\label{def:retract-module}
Let \(M\) be an \(R\)-module. A submodule \(N\) of \(M\) is said to be a
\emph{retract} of \(M\) if there exists an \(R\)-module morphism
\(\rho: M \to N\) such that \(\rho(n) = n\) for all \(n \in N\)---such
morphism is called a \emph{retraction}.
\end{definition}

\begin{proposition}[Direct summands \& retractions]
\label{prop:direct-summand-iff-retraction}
Given \(R\)-modules \(P\) and \(M\), the module \(M\) is a \emph{direct summand}
of \(P\) if and only if there exists a \emph{retraction} \(\rho: P \to M\), in
this case \(P \iso M \oplus \ker \rho\).
\end{proposition}

\begin{proof}
Suppose the retract \(\rho\) exists. Let \(p \in P\) be any element and consider
the element \(\rho(p) \in M\). Notice that
\(\rho(p - \rho(p)) = \rho(p) - \rho(\rho(p)) = \rho(p) - \rho(p) = 0\), thus
\(p - \rho(p) \in \ker \rho\). Since \(p = \rho(p) + (p - \rho(p))\), then
\(P = M + \ker \rho\). Moreover, if \(s \in S \cap \ker \phi\) it follows that
\(\rho(s) = s\) and \(\rho(s) = 0\), therefore \(s = 0\)---thus
\(S \cap \ker \phi = \{0\}\), and \(P = M \oplus \ker \rho\).

For the converse, suppose that \(M\) is a direct summand of \(P\) and let \(N\)
be its complement. Since any element \(p \in P\) can be written uniquely as a
sum \(p = m + n\) for \(m \in M\) and \(n \in N\), the map \(\rho: P \to M\)
given by \(m + n \mapsto m\) is well defined and unique---also being an
\(R\)-module morphism. Notice also that \(\rho|_M = \Id_M\).
\end{proof}

\begin{corollary}
\label{cor:direct-summand-iff-retraction}
If \(P = M \oplus N\) and \(M \subseteq A \subseteq P\), then
\[
A = M \oplus (A \cap N).
\]
\end{corollary}

\begin{proof}
Let \(\rho: P \to M\) be a retraction, so that \(\ker \rho = N\). Since
\(M \subseteq A\), then \(\rho|_A\) is a retraction between \(A\) and \(M\), and
\(\ker(\rho|_A) = A \cap N\). This shows that \(A \cap N\) is a complement of
\(M\) in \(A\) and hence \(A = M \oplus (A \cap N)\).
\end{proof}

\begin{corollary}
\label{cor:module-iso-ker-im}
Let \(M\) be an \(R\)-module, and \(p: M \to M\) be an idempotent
endomorphism (that is, \(p^2 = p\)). Then there exists a canonical isomorphisms
\[
M \iso \im p \oplus \ker p.
\]
\end{corollary}

\begin{proof}
Notice that the induced map \(\overline{p}: M \to \im p\) given by
\(\overline{p}(m) = p(m)\) is a morphism of \(R\)-modules such that
\(\overline{p}(\ell) = p(\ell) = \ell\) for all \(\ell \in \im p\)---since
\(p^2 = p\). This implies that \(\overline{p}\) is a retraction and from
\cref{prop:direct-summand-iff-retraction} it follows that
\(M \iso \im p \oplus \ker p\).
\end{proof}

\begin{proposition}
\label{prop:direct-summand-decomposition}
Let \(M\) be an \(R\)-module and \((M_j)_{j=1}^n\) be a family of
\(R\)-modules. Then
\[
M \iso M_1 \oplus \dots \oplus M_n
\]
if and only if there exists a collection of \(R\)-module morphisms
\((\phi_j: M \to M)_{j=1}^n\) such that \(\im \phi_j \iso M_j\) for all \(j\),
we have \(\phi_i \phi_j = 0\) for each pair \(i \neq j\), and
\(\sum_{j = 1}^n \phi_j = \Id_M\).
\end{proposition}

\begin{proof}
Suppose \(\psi: M_1 \oplus \dots \oplus M_n \isoto M\) is an isomorphism, then
every element of \(m \in M\) can be uniquely written as a sum
\(m = \sum_{j=1}^n a_j \psi((\delta_{ij} m_j)_{i=1}^n)\) for \(a_j \in R\) and
\(m_j \in M_j\). Define, for \(1 \leq j \leq n\), a morphism \(\phi_k: M \to M\)
given by
\[
\sum_{j=1}^n a_j \psi((\delta_{ij} m_j)_{i=1}^n)
\xmapsto{\phi_k} a_k \psi((\delta_{i k} m_k)_{i=1}^n).
\]
Clearly one has \(\phi_i \phi_j = 0\) for indices \(i \neq j\), and
\(\phi_1 + \dots + \phi_n = \Id_M\). Also, the map
\(\Phi_j: \im \phi_j \to M_j\) given by
\(a_j \psi((\delta_{i j} m_j)_{i=1}^n) \mapsto a_j m_j\) establishes an
isomorphism \(\im \phi_j \iso M_j\).

For the converse, suppose that the collection of morphisms \((\phi_j)_{j=1}^n\)
exist and satisfy the required properties. Let \(N\) be any \(R\)-module,
together with a family of morphisms \((\psi_j: N \to \im \phi_j)\). There
exists a uniquely defined morphism \(\eta: N \to M\) given by
\(n \mapsto \sum_{j=1}^n \psi_j(n)\) such that the following diagram
\[
\begin{tikzcd}
N \ar[d, "\eta"', dashed] \ar[rd, bend left, "\psi_j"] &\\
M \ar[r, "\phi_j"'] &\im \phi_j \iso M_j
\end{tikzcd}
\]
for all \(1 \leq j \leq n\). This shows that \(M\) satisfies the universal
property for the product of the family \((M_j)_{j=1}^n\), hence
\(M \iso M_1 \oplus \dots \oplus M_n\).
\end{proof}

\subsection{Exact Sequences}

Just like in the category of groups or vector spaces, we define an exact
sequence of modules as follows.

\begin{definition}[Exact sequence]
\label{def:exact-sequence-modules}
A sequence \((d_n: M_n \to M_{n-1})_{n \in \Z}\) of \(R\)-module morphisms is
said to form an \emph{exact sequence}
\[
\begin{tikzcd}
\dots \ar[r] &M_{n+1} \ar[r, "d_{n+1}"]
&M_n \ar[r, "d_n"] &M_{n-1} \ar[r] &\dots
\end{tikzcd}
\]
if for all \(n \in \Z\) we have \(\im d_{n+1} = \ker d_n\). In particular, a
sequence is said to be exact \emph{in} \(M_m\) if
\(\im d_{m + 1} = \ker d_m\)---thus an exact sequence is exact in each of its
modules.
\end{definition}

\begin{proposition}
\label{prop:exact-sequence-properties-zero-maps}
Let \(A\), \(B\) and \(C\) be \(R\)-modules. The following are properties
concerning exact sequences:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item A sequence
  \[
  \begin{tikzcd}
  0 \ar[r] &A \ar[r, "\phi"] &B
  \end{tikzcd}
  \]
  is exact if and only if \(\phi\) is \emph{injective}.
\item A sequence
  \[
  \begin{tikzcd}
  B \ar[r, "\psi"] & C \ar[r] &0
  \end{tikzcd}
  \]
  is exact if and only if \(\psi\) is \emph{surjective}.
\item A sequence
  \[
  \begin{tikzcd}
  0 \ar[r] &A \ar[r, "\kappa"] &B \ar[r] &0
  \end{tikzcd}
  \]
  is exact if and only if \(\kappa\) is an \emph{isomorphism}.
\end{enumerate}
\end{proposition}

\begin{proof}
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If the sequence is exact then \(\ker \phi = 0\) and \(\phi\) is
  injective. For the converse, if \(\phi\) is injective, then \(\ker \phi = 0\)
  and since the image of the morphism \(0 \to A\) must be zero, the exactness
  condition is satisfied.
\item If the sequence is exact then \(\im \psi = \ker(B \to 0) = B\) and
  \(\psi\) is surjective. If on the contrary we have \(\psi\) surjective, then
  again \(\im \psi = B\), and since the kernel of the morphism \(B \to 0\) is
  the whole module \(B\), it follows that the sequence is exact.
\item From the previous two items we have that \(\kappa\) is both injective and
  surjective, thus a bijection---and since bijective morphisms of \(R\)-modules
  are isomorphisms, the statement follows.
\end{enumerate}
\end{proof}

\begin{definition}
\label{def:exact-sequence-module}
An exact sequence of \(R\)-modules of the form
\[
\begin{tikzcd}
0 \ar[r] &A \ar[r, tail] &B \ar[r, two heads] &C \ar[r] &0
\end{tikzcd}
\]
is said to be a \emph{short exact sequence}. Moreover, we shall call such a
sequence an \emph{extension of \(A\) by \(C\)}---we may sometimes name \(B\) as
the ``extension''.
\end{definition}

\begin{proposition}[Isomorphism theorems]
\label{prop:isomorphism-thms-with-exact-sequences}
We now restate the isomorphism theorems of \(R\)-modules in terms of exact
sequences:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If \(0 \to A \overset{f}\mono B \overset{g}\epi C \to 0\) is a
  \emph{short exact sequence}, then there exists natural isomorphisms
  \[
  A \iso \im f \quad\text{ and }\quad B/{\im f} \iso C.
  \]
\item Let \(M\) be an \(R\)-module, and \(S\) and \(T\) be both submodules of
  \(M\). Then the following commutative diagram has short exact rows and the
  third vertical morphism is an isomorphism:
  \[
  \begin{tikzcd}
  0 \ar[r] &S \cap T \ar[d] \ar[r] &S \ar[r] \ar[d]
  &\frac{S}{S \cap T} \ar[r] \ar[d, "\dis"] &0
  \\
  0 \ar[r] &T \ar[r] &S + T \ar[r] \ar[r] &\frac{S + T}{T} \ar[r] &0
  \end{tikzcd}
  \]
\item Let \(M\) be an \(R\)-module, and consider submodules \(S\) and \(T\) of
  \(M\) such that \(S \subseteq T\). Then there exists a short exact sequence
  \[
  \begin{tikzcd}
  0 \ar[r] &S/T \ar[r, tail, "\iota"] &M/T \ar[r, two heads, "\pi"]
  &M/S \ar[r] &0
  \end{tikzcd}
  \]
\end{enumerate}
\end{proposition}

\begin{proof}
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item Since \(f\) is an injection, the induced morphism \(f: A \isoto \im f\) is
  an isomorphism. Moreover, since \(\ker g = \im f\) and \(g\) is a surjection,
  by the first isomorphism theorem we have \(B/{\im f} \iso C\).
\item By the second isomorphism theorem, the mapping
  \(S/(S \cap T) \to (S + T)/T\) given by \(s + S \cap T \mapsto s + T\) is an
  isomorphism.
\item Simply define \(\iota\) as the inclusion \(S/T \emb M/T\)---so that
  \(\im \iota = S/T\)---and \(\pi\) as the natural projection \(M/T \epi M/S\)
  mapping \(m + T \mapsto m + S\). Since \(\pi\) is surjective and, as argued in
  \cref{prop:third-iso-R-mod}, \(\ker \pi = S/T\). Therefore
  \(\ker \pi = \im \iota\)---the sequence is exact.
\end{enumerate}
\end{proof}

\begin{proposition}
\label{prop:induced-short-exact-sequence-direct-sum}
Let \(0 \to M_j \overset{\alpha_j}\mono N_j \overset{\beta_j}\epi L_j \to 0\) be
a short exact sequence of \(R\)-modules for all \(1 \leq j \leq n\). Then the
induced sequence
\[
\begin{tikzcd}
0 \ar[r] &\bigoplus_{j=1}^n M_j
\ar[r, tail, "\alpha"]
&\bigoplus_{j=1}^n N_j
\ar[r, two heads, "\beta"]
&\bigoplus_{j=1}^n L_j
\ar[r]
&0
\end{tikzcd}
\]
\end{proposition}

\begin{proof}
\begin{itemize}\setlength\itemsep{0em}
\item We first prove the injectivity of \(\alpha\). Notice that \((m_j)_j
  \in \ker \alpha\) if and only if \(\alpha_j(m_j) = 0\)---which implies in
  \(m_j = 0\) since \(\alpha_j\) is injective---therefore \((m_j)_j =
  0\). This implies in \(\ker \alpha = 0\), hence \(\alpha\) is injective.

\item For the surjectivity of \(\beta\), let
  \((\ell_j)_j \in \bigoplus_{j=1}^n L_j\) be any element. Since each
  \(\beta_j\) is surjective, there exists \(n_j \in N_j\) such that
  \(\beta_j(n_j) = \ell_j\). Now, if we consider the element
  \((n_j)_j \in \bigoplus_{j=1}^n N_j\), we obtain
  \(\beta(n_j)_j = (\beta_j(n_j))_j = (\ell_j)_j\).

\item For the exactness in \(\bigoplus_{j=1}^n N_j\) we prove that \(\im \alpha
  = \ker \beta\). Let \((m_j)_j \in \bigoplus_{j=1}^n\) be any element,
  then by definition \(\alpha(m_j)_j = (\alpha_j(m_j))_j \coloneq
  (n_j)_j\). Since each \(n_j \in \im \alpha_j\) and \(\im \alpha_j
  \subseteq \ker \beta_j\), it follows that \(\beta_j(n_j) = 0\). Then
  \(\beta(n_j)_j = (\beta_j(n_j))_j = 0\), which implies in \(\im \alpha
  \subseteq \ker \beta\).

  For the converse inclusion, let \((n_j)_j \in \ker \beta\) be any element---
  then in particular we must have \(n_j \in \ker \beta_j\). Since \(\ker \beta_j
  \subseteq \im \alpha_j\) for all \(1 \leq j \leq n\), then there exists \(m_j
  \in M_j\) such that \(\alpha_j(m_j) = n_j\). Therefore one obtains
  \(\alpha(m_j)_j = (\alpha_j(m_j))_j = (n_j)_j\), which shows that \(\ker \beta
  \subseteq \im \alpha\). Thus \(\im \alpha = \ker \beta\).
\end{itemize}
\end{proof}

\begin{lemma}
\label{lemma:big-X-of-short-exact-seq-iso-iff-iso}
Consider the diagram
\[
\begin{tikzcd}
0 \ar[rd] & & & &0
\\
&A \ar[rd, tail, "\alpha"] & &K \ar[ru] &
\\
& &X \ar[ru, two heads, "\kappa"] \ar[dr, two heads, "\beta"] & &
\\
&D \ar[ru, tail, "\delta"] & &B \ar[rd] &
\\
0 \ar[ru] & & & &0
\end{tikzcd}
\]
composed of short exact sequences of \(R\)-modules. Then
\(\kappa \alpha: A \to K\) is an isomorphism if and only if
\(\beta \delta: D \to B\) is an isomorphism.
\end{lemma}

\begin{proof}
From symmetry of the sequences we simply prove the forward implication. That is,
suppose \(\kappa \alpha\) is an isomorphism. For injectivity, let
\(d \in \ker \beta \delta\) be any element then \(\delta(d) \in \ker \beta\). By
exactness, there exists \(a \in A\) such that \(\alpha(a) =
\delta(d)\). However, since \(\delta(d) \in \ker \kappa\), then
\(\kappa \alpha(a) = 0\)---and by the injectivity of \(\kappa \alpha\) we find
that \(a = 0\), implying in \(\delta(d) = 0\). Since \(\delta\) is also
injective, then \(d = 0\), therefore \(\ker \beta \delta = 0\), proving that
\(\beta \delta\) is injective.

For surjectivity, take any \(b \in B\) and, since \(\beta\) is surjective, let
\(x \in X\) be such that \(\beta(x) = b\). Consider the element
\(\kappa(x) \in K\)---since \(\kappa \alpha\) is surjective, there exists
\(a \in A\) for which \(\kappa \alpha(a) = \kappa(x)\), thus
\(x - \alpha(a) \in \ker \kappa\). From exactness there must exist \(d \in D\)
for which \(\delta(d) = x - \alpha(a)\). With this in hands we obtain
\[
\beta \delta(d)
= \beta(x - \alpha(a))
= \beta(x) - \beta \alpha(a)
= \beta(x)
= b,
\]
proving that \(\beta \delta\) is surjective.
\end{proof}

\subsection{Split Exact Sequences}

\begin{definition}[Split sequence]
\label{def:split-short-exact-sequence}
A short exact sequence
\[
\begin{tikzcd}
0 \ar[r] &A \ar[r, tail, "\iota"] &B \ar[r, two heads, "p"] &C \ar[r] &0
\end{tikzcd}
\]
is said to be \emph{split} if \(p\) is a split epimorphism---that is, there
exists a morphism of \(R\)-modules (a section of \(p\)) \(s: C \mono B\) such
that \(p s = \Id_C\).
\end{definition}

\begin{proposition}[Split sequence extension]
\label{prop:splitting-of-sequence}
If the short exact sequence
\[
\begin{tikzcd}
0 \ar[r] &A \ar[r, tail, "\iota"] &B \ar[r, two heads, "p"] &C \ar[r] &0
\end{tikzcd}
\]
is split, then there exists a natural isomorphism of \(R\)-modules
\[
B \iso A \oplus C.
\]
\end{proposition}

\begin{proof}
Since the sequence is split, let \(s: C \to B\) be the section of \(p\). We'll
show that \(B = \im \iota \oplus \im s\). Let \(b \in B\) be any element, then
\begin{align*}
  p(b - sp(b))
  &= p(b) - p (s p(b)) \\
  &= p(b) - (p s) p(b) \\
  &= p(b) - \Id_C p(b) \\
  &= 0,
\end{align*}
therefore \(b - s p(b) \in \ker p\). Since the sequence is exact,
\(\im \iota = \ker p\), there exists \(a \in A\) such that
\(\iota(a) = b - s p(b)\)---thus \(b = \iota(a) + s p(b)\). From this we
conclude that \(B = \im \iota + \im s\). For this to be a direct summand, it
remains to prove that the intersection of the images is empty. Suppose that
\(x \in B\) is common to both images, so that there exists \(a \in A\) and
\(c \in C\) such that \(\iota(a) = x = s(c)\). Post-composing with \(p\) we get
\(p(x) = p \iota(a) = 0\), thus \(x \in \ker p\). Moreover, \(p s(c) = 0\) but
since \(p s = \Id_C\), then \(c = 0\)---thus \(s(c) = 0\) and \(x = 0\). We
conclude that
\[
B = \im \iota \oplus \im s,
\]
but \(\im \iota \iso A\) and \(\im s \iso C\)---since both are injective
maps---then \(B \iso A \oplus C\). Notice that this could also be extracted as a
consequence of \cref{cor:module-iso-ker-im}.
\end{proof}

\begin{remark}
\label{rem:converse-of-splitting-sequence-is-false}
It should be emphasized that the converse of \cref{prop:splitting-of-sequence}
\emph{does not hold} in general. For instance, consider cyclic free groups
\(A \coloneq \langle a \rangle\), \(B \coloneq \langle b \rangle\) and
\(C \coloneq \langle c \rangle\)---where both \(A\) and \(C\) have order \(2\),
while \(B\) has order \(4\). Endowing such groups with the structure of
\(\Z\)-modules, we can define morphisms \(\iota: A \to B\) mapping
\(a \mapsto 2 b\), and \(p: B \to C\) with \(b \mapsto c\), then the sequence
\(0 \to A \xrightarrow \iota B \xrightarrow p C \to 0\) is exact

\todo[inline]{Continue this, I can't continue today}
\end{remark}

\begin{proposition}[Equivalent definition for split sequences]
\label{prop:split-short-exact-sequence}
A short exact sequence \(0 \to A \xrightarrow \iota B \xrightarrow p C \to 0\)
is split if and only if \(\iota\) is a split monomorphism---that is, there
exists a morphism \(r: B \to A\) such that \(r \iota = \Id_A\). Moreover, if
\(s: C \to B\) is the section of \(p\), then
\[
s p + \iota r = \Id_B.
\]
\end{proposition}

\begin{proof}
Suppose the sequence splits and let \(s: C \mono B\) be a section of \(p\), then
by \cref{prop:splitting-of-sequence} we have \(B \iso \im \iota \oplus \im
s\). Since \(\iota\) and \(s\) are both injective maps, for every \(b \in B\)
there exists a unique pair \(a \in A\) and \(c \in C\) such that
\(b = \iota(a) + s(c)\). We define a map \(r: B \to A\) given by
\(r(b) = r(\iota(a) + s(c)) \coloneq a\). Therefore, for all \(a \in A\), we
have \(r \iota(a) = a\)---thus \(r\) is a retract of \(\iota\).

Suppose, for the converse, that \(\iota\) is a split monomorphism with a retract
\(r: B \epi A\). Notice that
\[
(\iota r)^2 = (\iota r) (\iota r) = \iota (r \iota) r = \iota \Id_B r
= \iota r,
\]
therefore \(\iota r: B \to B\) is an idempotent endomorphism. From
\cref{cor:module-iso-ker-im} we obtain that \(B = \ker(\iota r) \oplus \im(\iota
r)\). Since \(r\) is surjective, then \(\im(\iota r) = \im \iota\). Moreover,
since \(p\) is surjective, given any \(c \in C\), there exists \(b \in B\) such
that \(p(b) = c\). From the decomposition of \(B\), there exists \(k \in
\ker(\iota r)\) and \(a \in A\) such that \(b = k + \iota(a)\), therefore
\[
c = p(b) = p(k + \iota(a)) = p(k) + p \iota(a) = p(k),
\]
since \(\im \iota = \ker p\). Thus we may define a map \(s: C \to B\) as
\(s(c) = s(p(k)) \coloneq k\), so that \(s p = \Id_B\). We conclude that \(p\)
is a split epimorphism, which implies that the sequence is split.

For the second statement, notice that
\begin{align*}
(s p + \iota r)(b)
&= (s p + \iota r)(\iota(a) + s(c)) \\
&= (s p) f(a) + (s p) s(c) + (\iota r) \iota(a) + (\iota r) s(c) \\
&= s (p f(a)) + s (p s(c)) + \iota (r \iota(a)) + \iota (r s(c)) \\
&= \iota(a) + s(c),
\end{align*}
therefore \(s p + \iota r = \Id_B\).
\end{proof}

\begin{proposition}
\label{prop:sequence-end-free-module-is-split}
Let \(0 \to A \overset{f}\mono B \overset{g}\epi F \to 0\) be a short exact
sequence of \(R\)-modules. If \(F\) is a \emph{free} \(R\)-module, then the
sequence is \emph{split}. That is, every short exact sequence ending with a free
module is split.
\end{proposition}

\begin{proof}
Let \((e_j)_{j \in J}\) be a basis for \(F\). Since \(g\) is surjective, let
\((b_j)_{j \in J}\) be a collection such that \(g(b_j) = e_j\). By the free
module universal property, define the unique morphism \(\rho: F \to B\) mapping
\(\rho(e_j) \mapsto b_j\) for each \(j \in J\). Then notice that
\(g \rho(e_j) = g(b_j) = e_j\), thus we can again use the the uniqueness of the
morphism of the universal property of free modules to obtain that
\(g \rho = \Id_F\). Therefore we conclude that the sequence is split.
\end{proof}

\begin{example}
\label{exp:short-exact-seq-vect-spaces-split}
Every short exact sequence of vector spaces is split. Indeed, any vector space
admits a basis, which implies that a vector space is free---hence by
\cref{prop:sequence-end-free-module-is-split} we obtain the proposition.
\end{example}

\begin{proposition}
\label{prop:short-exact-finitely-generated}
If \(0 \to A \overset{f}\mono B \overset{g}\epi C \to 0\) is a short exact
sequence of \(R\)-modules, then the following are properties concerning finite
generation:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If both \(A\) and \(C\) are finitely generated modules, then \(B\) is
  finitely generated.

\item If \(B\) is finitely generated, then \(C\) is finitely generated.
\end{enumerate}
\end{proposition}

\begin{proof}
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item Let \(A \coloneq \langle a_1, \dots, a_n \rangle\) and
  \(C \coloneq \langle c_1, \dots, c_m \rangle\). Define \((b_j')_{j=1}^m\) be a
  collection of elements \(b_j \in g^{-1}(c_j)\)---which is ensured to exist by
  the surjectivity of \(g\)---and \((b_j)_{j=1}^n\) to be the collection
  \(b_j \coloneq f(a_j)\). We'll show that
  \(X \coloneq (b_1, \dots, b_n, b_1', \dots, b_m')\) is a generating set for
  \(B\). Let \(b \in B\) be any element, then since \(C\) is finitely generated,
  we can write
  \[
  g(b) = \sum_{j=1}^m c_j r_j'
  = \sum_{j=1}^m g(b_j') r_j'
  = \sum_{j=1}^m g(b_j' r_j')
  = g\Big(\sum_{j=1}^m b_j' r_j' \Big)
  \]
  for some collection of elements \(r_j' \in R\). Hence
  \(x \coloneq b - \sum_{j=1}^m b_j' r_j' \in \ker g\). Notice however that,
  since \(A\) is generated by \((a_j)_{j=1}^n\), then in particular
  \(\im f = \ker g\) is generated by \((b_j)_{j=1}^n\). Therefore there exists a
  collection \((r_j)_{j=1}^n\) of elements \(r_j \in R\) such that
  \[
  b = \sum_{j=1}^m b_j' r_j' + \sum_{j=1}^n b_j r_j.
  \]
  This shows that the finite set \(X\)---whose cardinality is
  \(m + n\)---generates the \(R\)-module \(B\), proving the proposition.

\item For item (b), one may notice that since the sequence is exact, then in
  particular \(g: B \epi C\) is surjective. Moreover, since \(B\) is finitely
  generated, we let \(B = \langle b_1, \dots, b_k \rangle\). Given any
  \(c \in C\) one has \(b \in B\) such that \(g(b) = c\). By the generating
  property, we have \(b = \sum_{j=1}^k b_j r_j\) for a collection
  \((r_j)_{j=1}^k\) of ring elements \(r_j \in R\). Therefore, by the morphism
  property of \(g\) we obtain
  \[
  c = g(b) = g\Big(\sum_{j=1}^k b_j r_j \Big) = \sum_{j=1}^k g(b_j) r_j.
  \]
  This shows that \(C\) is finitely generated by the collection
  \((g(b_j))_{j=1}^k\).
\end{enumerate}
\end{proof}

\subsection{Morphisms of Exact Sequences}

\begin{definition}[Morphisms of short exact sequences]
\label{def:morphism-short-exact-sequences}
A morphism between short exact sequences of \(R\)-modules
\(0 \to A \to B \to C \to 0\) and \(0 \to X \to Y \to Z \to 0\) is a triple
\((\alpha, \beta, \gamma)\), of morphisms of \(R\)-modules making the following
diagram commute
\[
\begin{tikzcd}
0 \ar[r] &A \ar[r, tail] \ar[d, "\alpha"']
&B \ar[r, two heads] \ar[d, "\beta"]
&C \ar[r] \ar[d, "\gamma"]
&0 \\
0 \ar[r] &X \ar[r, tail] &Y \ar[r, two heads] &Z \ar[r] &0
\end{tikzcd}
\]
\end{definition}

\begin{definition}[Equivalent sequences]
\label{def:equivalent-short-exact-sequences}
Two short exact sequences of \(R\)-modules \(0 \to A \mono B \epi C \to 0\) and \(0 \to X \mono Y
\epi Z \to 0\) are said to be \emph{equivalent} if \(A = X\), \(C = Z\) and
there exists an isomorphism of \(R\)-modules \(B iso Y\) such that the diagram
\[
\begin{tikzcd}
0 \ar[r] &A \ar[r, tail] \ar[d, equal]
&B \ar[r, two heads] \ar[d, "\dis"']
&C \ar[r] \ar[d, equal]
&0 \\
0 \ar[r]
&X \ar[r, tail]
&Y \ar[r, two heads]
&Z \ar[r]
&0
\end{tikzcd}
\]
commutes in \(\Mod{R}\).
\end{definition}

\begin{proposition}
\label{prop:unique-isomorphism-exact-sequences-right}
Let \(A \xrightarrow \alpha B \overset{\beta}\twoheadrightarrow C \to 0\) and
\(X \xrightarrow{\chi} Y \overset{\gamma}\twoheadrightarrow Z \to 0\) be exact
sequences. If there exists a surjective morphism \(f: A \epi X\) and an
isomorphism \(g: B \isoto Y\) such that \(g \alpha = \chi f\), then there exists
a \emph{unique isomorphism} \(h: C \to Z\) making the diagram
\[
\begin{tikzcd}
A \ar[r, "\alpha"] \ar[d, two heads, "f"']
&B \ar[r, two heads, "\beta"] \ar[d, "g"', "\dis"]
&C \ar[r] \ar[d, dashed, "h"', "\dis"]
&0 \\
X \ar[r, "\chi"'] &Y \ar[r, two heads, "\gamma"'] &Z \ar[r] &0
\end{tikzcd}
\]
commutative in \(\Mod{R}\).
\end{proposition}

\begin{proof}
Let \(c \in C\) be any element. Since \(\beta\) is surjective, there exists
\(b \in B\) such that \(\beta(b) = c\), thus we may define \(h: C \to Z\) as the
mapping \(c \mapsto \gamma g(a)\). To see that \(h\) is well defined, consider
\(b' \in \beta^{-1}(c)\), then \(\beta(b - b') = 0\) and since \(\ker \beta =
\im \alpha\), there exists \(a \in A\) such that \(\alpha(a) = b -
b'\). Therefore
\[
\gamma g(b) - \gamma g(b') = \gamma g(b - b')
= \gamma g \alpha(a) = \gamma \chi f(a)
= 0
\]
since \(\im \chi = \ker \gamma\)---thus \(h\) is indeed well defined, is a
\(R\)-module morphism, and makes the diagram commute. For the uniqueness of
\(h\), suppose \(h': C \to Z\) is another morphism making the diagram
commute---that is, \(h' \beta = \gamma g\). For any \(c \in C\), let
\(b \in \beta^{-1}(c)\) and notice that
\[
h'(c) = h'\beta(b) = \gamma g(b) = h \beta(b) = h(b),
\]
therefore \(h' = h\).

We now show that \(h\) is an isomorphism. Let \(c \in \ker h\) be any element,
and \(b \in \beta^{-1}(c)\), then \(0 = h \beta(b) = \gamma g(b)\)---therefore
\(g(b) \in \ker \gamma = \im \chi\), thus there exists \(x \in X\) such that
\(\chi(x) = g(b)\). From the surjectivity of \(f\), there exists \(a \in A\)
such that \(f(a) = x\). Since the first square is commutative,
\[
g \alpha(a) = \chi f(a) = \chi(x) = g(b),
\]
but since \(g\) is injective then \(\alpha(a) = b\). Therefore we conclude that
\[
c = \beta(b) = \beta \alpha(a) = 0,
\]
since \(\ker \beta = \im \alpha\). Hence \(\ker h = 0\) and \(h\) is injective.

For the surjectivity of \(h\), let \(z \in Z\) be any element. Since \(\gamma\)
is surjective, let \(y \in Y\) be such that \(\gamma(y) = z\), then from the
surjectivity of \(g\), we let \(b \in B\) be an element such that \(g(b) = y\),
then from the commutativity of the second square we obtain
\[
h \beta(b) = \gamma g(b) = \gamma(y) = z
\]
thus \(\beta(b) \in C\) has image \(z\) under \(h\), and \(h\) is therefore
surjective.
\end{proof}

\begin{proposition}
\label{prop:unique-isomorphism-exact-sequences-left}
Let \(0 \to A \overset{\alpha}\mono B \xrightarrow \beta C\) and
\(0 \to X \overset{\chi}\mono Y \xrightarrow \gamma Z\) be exact sequences. If
there exists morphisms \(g: B \to Y\) and \(h: C \to Z\) such that
\(\gamma g =h \beta\), then there exists a \emph{unique} morphism \(f: A \to X\)
such that
\[
\begin{tikzcd}
0 \ar[r]
&A \ar[r, tail, "\alpha"] \ar[d, dashed, "f"']
&B \ar[r, "\beta"] \ar[d, "g"']
&C \ar[d, "h"']
\\
0 \ar[r]
&X \ar[r, tail, "\chi"']
&Y \ar[r, "\gamma"']
&Z
\end{tikzcd}
\]
commutes in \(\Mod{R}\). Moreover, if both \(g\) and \(h\) are isomorphisms,
then \(f\) is an \emph{isomorphism}.
\end{proposition}

\begin{proof}
Let \(a \in A\) be any element and define \(\alpha(a) \coloneq b\). Since the
top row is exact we have \(b \in \ker \beta\). From the commutativity of the
second square, we find
\[
\gamma g(b) = h \beta(b) = h(0) = 0
\]
therefore \(g(b) \in \ker \gamma\). Since the bottom row is exact, there must
exist \(x \in X\) such that \(\chi(x) = g(b)\). Define a map \(f: A \to X\) by
sending \(a \mapsto x\) as described above. From the injectivity of \(\alpha\)
and \(\chi\), one has that \(\alpha^{-1}(b) = \{a\}\) and
\(\chi^{-1}(g(b)) = \{x\}\), therefore \(f\) is well defined. If
\(a, a' \in A\), and \(r \in R\) are any elements, defining
\(\alpha(a) \coloneq b\) and \(\alpha(a') \coloneq b'\)
\(\alpha(a r + a') = \alpha(a) r + \alpha(a') = b r + b'\). Moreover,
\(g(b), g(b') \in \ker \gamma\) thus there exists \(x, x' \in X\) such that
\(\chi(x) = g(b)\) and \(\chi(x') = g(b')\). Therefore
\[
f(a r + a') = x r + x' = f(a) r + f(a'),
\]
which shows that \(f\) is a morphism of \(R\)-modules. For the commutativity of
the first square we have, for any \(a \in A\),
\[
g \alpha(a) = g(b) = \chi(x) = \chi f(a).
\]

For the second statement, suppose that both \(g\) and \(h\) are
isomorphisms. Let \(a \in \ker f\) be any element, then if \(\alpha(a) = b\) we
obtain by commutativity of the first square that
\[
g \alpha(a) = g(b) = \chi f(a) = \chi(0) = 0,
\]
but since \(g\) is injective, then \(b = 0\). Therefore \(\alpha(a) = 0\), which
implies in \(a = 0\), since \(\alpha\) is injective. This shows that \(\ker f =
0\) and thus \(f\) is injective. For surjectivity, let \(x \in X\) be any
element, and let \(y \coloneq \chi(x)\) so that \(y \in \ker \gamma\) by the
exactness of the bottom row. Since \(g\) is surjective, let \(b \in B\) such
that \(g(b) = y\). From the commutativity of the second square we have
\[
h \beta(b) = \gamma g(b) = \gamma(y) = 0,
\]
therefore \(\beta(b) \in \ker h\). Since \(h\) is injective, then
\(\beta(b) = 0\) and thus \(\beta \in \im \alpha\) from the exactness of the top
row. Let \(a \in A\) be such that \(\alpha(a) = b\), then from the commutativity
of the first square we get
\[
\chi f(a) = g \alpha(a) = g(b) = y.
\]
Since \(\chi\) is injective and \(\chi(x) = y\), then \(f(a) = x\). Therefore
\(f\) is an isomorphism.
\end{proof}

\begin{proposition}[Five lemma]
\label{prop:five-lemma}
Consider the following commutative diagram in \(\Mod{R}\), whose \emph{rows are
  exact}:
\[
\begin{tikzcd}
A_1 \ar[r] \ar[d, "\phi_1"]
&A_2 \ar[r] \ar[d, "\phi_2"]
&A_3 \ar[r] \ar[d, "\phi_3"]
&A_4 \ar[r] \ar[d, "\phi_4"]
&A_5 \ar[d, "\phi_5"]
\\
B_1 \ar[r]
&B_2 \ar[r]
&B_3 \ar[r]
&B_4 \ar[r]
&B_5
\end{tikzcd}
\]
The following properties hold:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If \(\phi_2\) and \(\phi_4\) are \emph{surjective} and \(\phi_5\) is
  \emph{injective}, then \(\phi_3\) is \emph{surjective}.
\item If \(\phi_2\) and \(\phi_4\) are \emph{injective} and \(\phi_1\) is
  \emph{surjective}, then \(\phi_3\) is \emph{injective}.
\item If \(\phi_1\), \(\phi_2\), \(\phi_4\) and \(\phi_5\) are
  \emph{isomorphisms}, then \(\phi_3\) is an \emph{isomorphism}.
\end{enumerate}
\end{proposition}

\begin{proof}
Let \(\alpha_j: A_j \to A_{j+1}\) and \(\beta_j: B_j \to B_{j+1}\) for
\(1 \leq j \leq 4\) be the morphisms shown in the diagram. We prove each item:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item Let \(b_3 \in B_3\) be any element, and define \(b_4 \coloneq
  \beta_3(b_3)\). Since \(\phi_4\) is surjective, there exists \(a_4 \in A_4\)
  such that \(\phi_4(a_4) = b_4\). From the exactness of the bottom row we have
  \(b_4 \in \ker \beta_4\), since \(b_4 \in \im \beta_3\). By the commutativity
  of the forth square we have
  \[
  \phi_5 \alpha_4(a_4) = \beta_4 \phi_4 (a_4) = \beta_4(b_4) = 0
  \]
  therefore \(\alpha_4(a_4) \in \ker \phi_5\). Since \(\phi_5\) is injective,
  then \(a_4 \in \ker \alpha_4\). By the exactness of the top row, there exists
  \(a_3 \in A_3\) such that \(\alpha_3(a_3) = a_4\). From the commutativity of
  the third square we get
  \[
  \beta_3 \phi_3(a_3) = \phi_4 \alpha_3(a_3) = \phi_4(a_4) = b_4.
  \]

  Since \(\beta_3(b_3) = b_4 = \beta_3 \phi_3(a_3)\), then
  \(\phi_3(a_3) - b_3 \in \ker \beta_3\). Using again the exactness of the
  bottom row, there exists \(b_2 \in B_2\) such that
  \(\beta_2(b_2) = \phi_3(a_3) - b_3\). Since \(\phi_2\) is surjective, there
  exists \(a_2 \in A_2\) such that \(\phi_2(a_2) = b_2\). From the commutativity
  of the second square one has
  \[
  \phi_3 \alpha_2(a_2) = \beta_2 \phi_2(a_2) = \beta_2(b_2) = \phi_3(a_3) - b_3,
  \]
  which implies in \(\phi_3(a_3 - \alpha_2(a_2)) = b_3\). This proves the
  surjectivity of \(\phi_3\).

\item Let \(a_3 \in \ker \phi_3\) be any element. By the commutativity of the
  third square we obtain
  \[
  \phi_4 \alpha_3 (a_3) = \beta_3 \phi_3(a_3) = \beta_3(0),
  \]
  thus \(\alpha_3(a_3) \in \ker \phi_4\)---but since \(\phi_4\) is injective,
  then \(a_3 \in \ker \alpha_3\). From the exactness of the top row, there
  exists \(a_2 \in A_2\) such that \(\alpha_2(a_2) = a_3\). By the commutativity
  of the second square we have
  \[
  \beta_2 \phi_2(a_2) = \phi_3 \alpha_2(a_2) = \phi_3(a_3) = 0,
  \]
  hence \(\phi_2(a_2) \in \ker \beta_2\). From the exactness of the bottom row
  there must exist \(b_1 \in B_1\) such that \(\beta_1(b_1) =
  \phi_2(a_2)\). Since \(\phi_1\) is surjective, let \(a_1 \in A_1\) be such
  that \(\phi_1(a_1) = b_1\). Using the commutativity of the first square we
  obtain
  \[
  \phi_2 \alpha_1(a_1) = \beta_1 \phi_1(a_1) = \beta_1(b_1) = \phi_2(a_2),
  \]
  therefore \(\phi_2(\alpha_1(a_1) - a_2) = 0\). Since \(\phi_2\) is injective,
  then \(\alpha_1(a_1) = a_2\). From exactness of the top row, we have \(a_2 \in
  \ker \alpha_2\), but since \(\alpha_2(a_2) = a_3\), then \(a_3 = 0\). This
  shows that \(\ker \phi_3 = 0\), thus \(\phi_3\) is injective.

\item This last item is a direct consequence of the above items (a) and (b).
\end{enumerate}
\end{proof}

\begin{proposition}[\(3 \times 3\) lemma]
\label{prop:3-by-3-lemma}
Consider the following commutative diagram in \(\Mod{R}\), whose \emph{columns
  are exact}:
\[
\begin{tikzcd}
&0 \ar[d] &0 \ar[d] &0 \ar[d] &
\\
0 \ar[r]
&A \ar[r, "\alpha"] \ar[d, tail, "f_1"']
&B \ar[r, "\beta"] \ar[d, tail, "g_1"']
&C \ar[r] \ar[d, tail, "h_1"]
&0
\\
0 \ar[r]
&X \ar[r, "\chi"] \ar[d, two heads, "f_2"']
&Y \ar[r, "\gamma"] \ar[d, two heads, "g_2"']
&Z \ar[r] \ar[d, two heads, "h_2"]
&0
\\
0 \ar[r]
&L \ar[r, "\lambda"'] \ar[d]
&S \ar[r, "\sigma"'] \ar[d]
&D \ar[r] \ar[d]
&0
\\
&0 &0 &0 &
\end{tikzcd}
\]
Then, the following properties hold:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If the \emph{bottom two rows are exact}, then the \emph{top row is exact}.
\item If the \emph{top two rows are exact}, then the \emph{bottom row is exact}.
\end{enumerate}
\end{proposition}

\begin{proof}
Let's diagram chase!
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item First we show that \(\im \alpha \subseteq \ker \beta\). Let \(a \in A\) be
  any element and define \(b \coloneq \alpha(a)\), \(x \coloneq f_1(a)\) and \(y
  \coloneq \chi(x)\). From the commutativity of the top left square:
  \[
  g_1\alpha(a) = \chi f_1(a) = \chi(x) = y,
  \]
  thus \(g_1(b) = y\). Since \(y \in \im \chi\), by the exactness of the middle
  row we obtain \(y \in \ker \gamma\). From the commutativity of the top right
  square:
  \[
  h_1 \beta(b) = \gamma g_1(b) = \gamma(y) = 0,
  \]
  therefore \(\beta(b) \in \ker h_1\), and since \(h_1\) is injective, we
  conclude that \(\beta(b) = 0\). Therefore \(\im \alpha \subseteq \ker \beta\)
  as wanted.

  For the final part, we show that \(\ker \beta \subseteq \im \alpha\). Let
  \(b \in \ker \beta\) be any element. From the commutativity of the top right
  square:
  \[
  \gamma g_1(b) = h_1 \beta(b) = h_1(0) = 0
  \]
  therefore \(g_1(b) \in \ker \gamma\). From the exactness of the middle row
  there exists \(x \in X\) such that \(\chi(x) = g_1(b)\). From both the
  commutativity of the bottom left square and the exactness of the middle row:
  \[
  \gamma f_2(x) = g_2 \chi(x) = g_2 g_1(b) = 0,
  \]
  hence \(f_2(x) \in \ker \gamma\), but since \(\gamma\) is injective we
  conclude that \(x \in \ker f_2\). From the exactness of the left column there
  exists \(a \in A\) such that \(f_1(a) = x\). By the commutativity of the top
  left square:
  \[
  g_1 \alpha(a) = \chi f_1(a) = \chi(x) = y.
  \]
  Since \(g_1\) is injective and \(g_1(b) = y\), then \(\alpha(a) = b\). Thus
  \(\ker \beta \subseteq \im \alpha\).

\item We show that \(\im \lambda \subseteq \ker \sigma\). Let \(\ell \in L\) be
  any element and define \(s \coloneq \gamma(\ell)\). Since \(f_2\) is
  surjective, let \(x \in X\) be such that \(f_2(x) = \ell\). From the exactness
  of the middle row we have \(y \coloneq \chi(x) \in \ker \gamma\). By the
  commutativity of the bottom left square:
  \[
g_2\chi(x) = \lambda f_2(x) = \lambda(\ell) = s,
  \]
  therefore \(g_2(y) = s\). Now using the commutativity of the bottom right
  square:
  \[
\sigma g_2(y) = h_2 \gamma(y) = h_2(0) = 0,
  \]
  then \(\sigma(s) = 0\), hence \(\im \lambda \subseteq \ker \sigma\).

  Finally, we show that \(\ker \sigma \subseteq \im \lambda\). Let
  \(s \in \ker\sigma\) be any element. Since \(g_2\) is surjective, let
  \(y \in Y\) be such that \(g_2(y) = s\). From the commutativity of the bottom
  right square:
  \[
  h_2 \gamma(y) = \sigma g_2(y) = \sigma(s) = 0,
  \]
  therefore \(\gamma(y) \in \ker h_2\). From the exactness of the right column,
  there exists \(c \in C\) such that \(h_1(c) = \gamma(y)\). Since \(\beta\) is
  surjective, there exists \(b \in B\) for which \(\beta(b) = c\). Using the
  commutativity of the top right square:
  \[
  \gamma g_1(b) = h_1 \beta(b) = h_1(c) = \gamma(y),
  \]
  hence \(\gamma(y - g_1(b)) = 0\). By the exactness of the middle row, we can
  find \(x \in X\) such that \(\chi(x) = y - g_1(b)\). Applying the
  commutativity of the bottom left square:
  \[
  \lambda f_2(x) = g_2 \chi(x)
  = g_2(y - g_1(b)) = g_2(y) - g_2 g_1(b) = g_2(y) = s,
  \]
  therefore \(s \in \im \lambda\). Thus indeed
  \(\ker \sigma \subseteq \im \lambda\).
\end{enumerate}
\end{proof}

\begin{proposition}
\label{prop:top-exact-iff-bottom-exact}
Consider the following commutative diagram in \(\Mod{R}\):
\[
\begin{tikzcd}
0 \ar[r]
&A \ar[r, "\alpha"] \ar[d, "\dis"', "\phi_1"]
&B \ar[r, "\beta"]  \ar[d, "\dis"', "\phi_2"]
&C \ar[r]           \ar[d, "\dis", "\phi_3"']
&0 \\
0 \ar[r]
&X \ar[r, "\chi"']
&Y \ar[r, "\gamma"']
&Z \ar[r]
&0 \\
\end{tikzcd}
\]
Then the top row is exact if and only if the bottom row is exact.
\end{proposition}

\begin{proof}
(\(\implies\)) Suppose the top row is exact. We prove that the bottom row is
exact in two parts:
\begin{itemize}\setlength\itemsep{0em}
\item We show that \(\im \chi \subseteq \ker \gamma\). Let \(x \in X\) be any
  element, and define \(y \coloneq \chi(x)\). Since \(\phi_1\) is surjective,
  let \(a \in A\) be such that \(\phi_1(a) = x\). By the commutativity of the
  first square:
  \[
  \phi_2 \alpha(a) = \chi \phi_1(a) = \chi(x) = y.
  \]
  From the exactness of the top row we have \(b \coloneq \alpha(a) \in \ker
  \beta\). Hence, by the commutativity of the second square:
  \[
\gamma \phi_2(b) = \gamma(y) = \phi_3 \beta(b) = \phi_3(0) = 0,
  \]
  thus \(y \in \ker \gamma\)---which implies in \(\im \chi \subseteq \ker
  \gamma\).
\item We now show that \(\ker \gamma \subseteq \im \chi\). Let \(y \in \ker
  \gamma\) be any element. Since \(\phi_2\) is surjective, let \(b \in B\) be
  such that \(\phi_2(b) = y\). From the commutativity of the second square:
  \[
\phi_3 \beta(b) = \gamma \phi_2(b) = \gamma(y) = 0,
  \]
  thus \(\beta(b) \in \ker \phi_3\)---but since \(\phi_3\) is injective, then
  \(b \in \ker \beta\). From the exactness of the top row we find \(a \in A\)
  such that \(\alpha(a) = b\). Using the commutativity of the first square:
  \[
  \chi \phi_1(a) = \phi_2 \alpha(a) = \phi_2(b) = y,
  \]
  therefore \(y \in \im \chi\) and \(\ker \gamma \subseteq \im \chi\).
\end{itemize}

(\(\Leftarrow\)) If on the contrary we assume that the bottom row is exact,
since \(\phi_1\), \(\phi_2\) and \(\phi_3\) are invertible, one can simply
consider the following commutative diagram:
\[
\begin{tikzcd}
0 \ar[r]
&X \ar[r, tail, "\chi"] \ar[d, "\dis"', "\phi_1^{-1}"]
&Y \ar[r, two heads, "\gamma"]  \ar[d, "\dis"', "\phi_2^{-1}"]
&Z \ar[r]           \ar[d, "\dis", "\phi_3^{-1}"']
&0 \\
0 \ar[r]
&A \ar[r, "\alpha"']
&B \ar[r, "\beta"']
&C \ar[r]
&0 \\
\end{tikzcd}
\]
We can now apply the first part of the proof and conclude that the sequence of
modules \(0 \to A \to B \to C \to 0\) is exact.
\end{proof}

\subsection{Exact Functors}

\begin{definition}
\label{def:left-exact-functor}
Let \(F: \Mod{R} \to \Ab\) be a covariant functor, and
\(G: \Mod{R}^{\op} \to \Ab\) be a contravariant functor. Consider a sequence of
\(R\)-modules
\[
\begin{tikzcd}
0 \ar[r] &A \ar[r, "f"] &B \ar[r, "g"] &C \ar[r] &0
\end{tikzcd},
\]
We define the following notions:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If \(0 \to A \to B \to C\) is \emph{exact}, the functor \(F\) is said to
  be \emph{left exact} if the induced sequence of abelian groups
  \[
  \begin{tikzcd}
  0 \ar[r] &F A \ar[r, "F f"] &F B \ar[r, "F g"] &F C
  \end{tikzcd}
  \]
  is exact. Dually, \(G\) is said to be \emph{right exact} if
  \[
  \begin{tikzcd}
  G C \ar[r, "G g"] &G B \ar[r, "G f"] &G A \ar[r] &0
  \end{tikzcd}
  \]
  is an exact sequence.
\item If \(A \to B \to C \to 0\) is \emph{exact}, the functor \(F\) is said to
  be \emph{right exact} if the induced sequence of abelian groups
  \[
  \begin{tikzcd}
  F A \ar[r, "F f"] &F B \ar[r, "F g"] &F C \ar[r] &0
  \end{tikzcd}
  \]
  is exact. Dually, \(G\) is said to be \emph{left exact} if
  \[
  \begin{tikzcd}
  0 \ar[r] &G C \ar[r, "G g"] &G B \ar[r, "G f"] &G A
  \end{tikzcd}
  \]
  is an exact sequence.
\item If \(0 \to A \to B \to C \to 0\) is \emph{short exact}, the functor \(F\)
  is said to be \emph{exact} if the induced sequence of abelian groups
  \[
  \begin{tikzcd}
  0 \ar[r] &F A \ar[r, "F f"] &F B \ar[r, "F g"] &F C \ar[r] &0
  \end{tikzcd}
  \]
  is exact. Analogously, \(G\) is said to be \emph{exact} if
  \[
  \begin{tikzcd}
  0 \ar[r] &G C \ar[r, "G g"] &G B \ar[r, "G f"] &G A \ar[r] &0
  \end{tikzcd}
  \]
\end{enumerate}
\end{definition}

\begin{proposition}
\label{prop:hom-functors-left-exact}
Given any \(R\)-module \(M\), the functors
\[
\Hom_{\Mod{R}}(M, -): \Mod{R} \longrightarrow \Ab
\quad\text{ and }\quad
\Hom_{\Mod{R}}(-, M): \Mod{R}^{\op} \longrightarrow \Ab
\]
are both left-exact.
\end{proposition}

\begin{proof}
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item We first show that \(\Hom_{\Mod{R}}(M, -)\) is exact. Let
  \(0 \to A \overset{f}\mono B \xrightarrow g C\) be an exact sequence of
  \(R\)-modules, and consider the induced sequence of abelian groups
  \[
  \begin{tikzcd}
  0 \ar[r] &\Hom_{\Mod{R}}(M, A) \ar[r, tail, "f_{*}"] &\Hom_{\Mod{R}}(M, B)
  \ar[r, "g_{*}"] &\Hom_{\Mod{R}}(M, C).
  \end{tikzcd}
  \]
  First we show that \(f_{*}\) is injective. Let \(\ell \in \ker f_{*}\) be any
  morphism, then by definition we have \(f_{*}(\ell) = f \ell = 0\). Since \(f\)
  is injective, we have \(\ker f = 0\), which implies in
  \(\im \ell = 0\)---hence \(\ell = 0\). This shows that \(\ker f_{*} = 0\),
  therefore \(f_{*}\) is an injective map.

  To show that the induced sequence is exact in \(\Hom_{\Mod{R}}(M, B)\), we
  prove that \(\im f_{*} = \ker g_{*}\). Let \(\ell \in \im f_{*}\) be any
  element and let \(k \in \Hom_{\Mod{R}}(M, A)\) be such that
  \(f_{*}(k) = f k = \ell\). Since the original sequence is exact, we have
  \[
  g_{*}(\ell) = g \ell = g (f k) = 0
  \]
  since \(\im f = \ker g\). Therefore
  \(\ell \in \ker g_{*}\) and \(\im f_* \subseteq \ker g_{*}\).

  For the converse of this inclusion, let \(h \in \ker g_{*}\) be any map so
  that \(g h(m) = 0\) for all \(m \in M\)---therefore \(h(m) \in \ker g\) and by
  exactness this means that there must exist \(a \in A\) such that \(f(a) = m\),
  which is unique since \(f\) is an injective map. Define \(p: M \to A\) by
  mapping \(m \mapsto a\) if \(h(m) = f(a)\). To check that \(p\) is a morphism
  of modules, let \(m, m' \in M\) be elements and let \(a, a' \in A\) be such
  that \(h(m) = f(a)\) and \(h(m') = f(a')\). Then since
  \[
  h(m + m') = h(m) + h(m') = f(a) + f(a') = f(a + a'),
  \]
  then \(p(m + m') = a + a' = p(m) + p(m')\). If \(r \in R\) is any ring
  element, then one also has
  \[
  h(m r) = h(m) r = f(a) r = f(a r),
  \]
  therefore \(p(m r) = a r = p(m) r\). Then we conclude that \(p \in
  \Hom_{\Mor{R}}(M, A)\) and therefore \(f_{*}(p) = h\), showing that \(h \in
  \im f_{*}\) and that \(\ker g_{*} \subseteq \im f_{*}\). This finishes the
  proof that \(\im f_{*} = \ker g_{*}\).

\item We now prove the left exactness of the contravariant functor
  \(\Hom_{\Mor{R}}(-, M)\). Let \(A \xrightarrow i B \overset{p}\epi C \to 0\)
  be an exact sequence of \(R\)-modules, and consider the induced sequence of
  abelian groups
  \[
  \begin{tikzcd}
  0 \ar[r] &\Hom_{\Mod{R}}(C, M) \ar[r, tail, "p^{*}"] &\Hom_{\Mod{R}}(B, M)
  \ar[r, "i^{*}"] &\Hom_{\Mod{R}}(A, M).
  \end{tikzcd}
  \]
  We first show the injectivity of \(p^{*}\). Let \(h \in \ker p^{*}\) be any
  map, then for every \(b \in B\) one has \(h p(b) = 0\), therefore
  \(\im p \subseteq \ker h\). Since \(p\) is surjective, \(\im p = C\) and since
  \(\ker h \subseteq C\), then we conclude that \(\ker h = \im p = C\) and
  therefore \(h = 0\).

  Let's now show that \(\im p^{*} = \ker i^{*}\). If
  \(g \in \Hom_{\Mod{R}}(C, M)\) is any map, then one has
  \[
  i^{*} p^{*}(g) = i^{*}(g p) = (g p) i = g (p i) = 0,
  \]
  from the fact that \(\im i = \ker p\). Therefore \(g \in \ker i^{*}\) and
  \(\im p^{*} \subseteq \ker i^{*}\). For the converse, take
  \(g \in \ker i^{*}\). Define a map \(f: C \to Y\) by \(c \mapsto g(b)\) if
  \(c = p(b)\)---an element \(b \in B\) with such property is ensured to exist
  by the surjectivity of \(p\). To check that \(f\) is well defined, let
  \(b, b' \in B\) be any two elements with \(p(b) = p(b')\)---then
  \(p(b - b') = 0\), which implies that there exists \(a \in A\) such that
  \(i(a) = b - b'\). Moreover, since \(i^{*}(g) = g i = 0\), then
  \[
  g i(a) = g(b - b') = g(b) - g(b') = 0,
  \]
  therefore \(f(b) = f(b')\). To show that \(f\) is a morphism of \(R\)-modules,
  let \(r \in R\) and \(c, c' \in C\) be any elements with corresponding
  \(b, b' \in B\) for which \(p(b) = c\) and \(p(b') = c'\). Then
  \(p(b + b') = c + c'\) and then
  \[
  f(c + c') = g(b + b') = g(b) + g(b') = f(c) + f(c').
  \]
  Moreover, we have \(p(b r) = p(b) r = c r\), hence
  \[
  f(c r) = g(b r) = g(b) r = f(c) r.
  \]
  This shows that \(f\) is indeed \(R\)-linear. Therefore we can finally note
  that \(p^{*}(f) = f p = g\) so that \(g \in \im p^{*}\), hence
  \(\ker i^{*} \subseteq \im p^{*}\).
\end{enumerate}
\end{proof}

\begin{remark}
\label{rem:not-right-exact}
The functors \(\Hom_{\Mod{R}}(M, -)\) and \(\Hom_{\Mod{R}}(-, M)\) are \emph{not
  right-exact}. In other words, if \(0 \to A \xrightarrow f B\) is an exact
sequence of \(R\)-modules, \emph{it is not always true} that the sequence of
abelian groups
\(\Hom_{\Mod{R}}(A, M) \xrightarrow {f^{*}} \Hom_{\Mod{R}}(B, M) \to 0\) is exact.

For instance, one can take the exact sequence \(0 \to \Z \overset f \mono \Z\)
where \(f(x) \coloneq 2 x\), and the module \(M \coloneq \Z/2\Z\), so that
\(\Hom_{\Mod{\Z}}(\Z, M) = \{0, \pi\}\)---where \(\pi: \Z \epi \Z/2\Z\) is the
natural projection. Therefore the induced map
\(f^{*}: \Hom_{\Mod{\Z}}(\Z, M) \to \Hom_{\Mod{\Z}}(\Z, M)\) is \emph{not}
surjective, since \(\pi \mapsto \pi f = 0\).
\end{remark}

\begin{proposition}[Converse of \cref{prop:hom-functors-left-exact}]
\label{prop:hom-exact-then-sequence-exact}
Consider \(R\)-modules \(A\), \(B\) and \(C\), and morphisms of
\(R\)-modules \(f: A \to B\) and \(g: B \to C\). We have the following two
properties concerning the functors \(\Hom_{\Mod{R}}(M, -)\) and
\(\Hom_{\Mod{R}}(-, M)\):
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item If the sequence of abelian groups
  \[
  \begin{tikzcd}
  0 \ar[r] &\Hom_{\Mod{R}}(M, A) \ar[r, tail, "f_{*}"] &\Hom_{\Mod{R}}(M, B)
  \ar[r, "g_{*}"] &\Hom_{\Mod{R}}(M, C)
  \end{tikzcd}
  \]
  is \emph{exact for every} \(M \in \Mod{R}\), then the corresponding sequence
  of \(R\)-modules
  \[
  \begin{tikzcd}
  0 \ar[r] &A \ar[r, tail, "f"] &B \ar[r, "g"] &C
  \end{tikzcd}
  \]
  is also \emph{exact}.

\item If the sequence of abelian groups
  \[
  \begin{tikzcd}
  0 \ar[r] &\Hom_{\Mod{R}}(C, M) \ar[r, tail, "g^{*}"] &\Hom_{\Mod{R}}(B, M)
  \ar[r, "f^{*}"] &\Hom_{\Mod{R}}(A, M).
  \end{tikzcd}
  \]
  is \emph{exact for every} \(M \in \Mod{R}\), then the corresponding sequence
  of \(R\)-modules
  \[
  \begin{tikzcd}
  A \ar[r, "f"] &B \ar[r, two heads, "g"] &C \ar[r] &0
  \end{tikzcd}
  \]
  is also \emph{exact}.
\end{enumerate}
\end{proposition}

\begin{proof}
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item We first show the injectivity of \(f\). Let \(M \coloneq \ker f\) and
  consider the natural inclusion \(\iota \in \Hom_{\Mod{R}}(M, A)\), then
  \(f_{*}(\iota) = f \iota = 0\), but since \(f_{*}\) is injective then
  \(\iota = 0\)---which implies in \(\ker f = 0\).

  For the proof that \(\im f = \ker g\), take \(M \coloneq \im f\) and consider
  the natural inclusion \(i \in \Hom_{\Mod{R}}(M, B)\). Since \(f\) is
  injective, the induced map \(\overline{f}: A \to \im f\) is a bijection,
  therefore one may define \(\ell: \im f \to A\) by
  \(\ell = (\overline{f})^{-1}\). Notice that \(f_{*}(\ell) = f \ell = i\),
  therefore \(i \in \im f_{*}\). Since \(\im f_{*} \subseteq \ker g_{*}\), then
  \(g_{*}(i) = g i = 0\), which implies in \(\im f \subseteq \ker g\).

  For the converse inclusion, define \(M \coloneq \ker g\) and consider the
  canonical inclusion \(j \in \Hom_{\Mod{R}}(M, B)\), so that
  \(g_{*}(j) = g j = 0\). From the exactness of the sequence of abelian groups,
  there must exist \(h \in \Hom_{\Mod{R}}(M, A)\) such that
  \(f_{*}(\ell) = f \ell = j\)---therefore, for all \(b \in \ker g\) there
  exists \(\ell(b) \in A\) such that \(f(\ell(b)) = b\), thus
  \(\ker g \subseteq \im f\).

\item First we prove that \(g\) is surjective. Since the sequence is exact for
  all modules \(M\), take \(M \coloneq C/{\im g}\) and let \(\pi: C \epi M\) be
  the natural projection morphism. Then we have \(g^{*}(\pi) = \pi g = 0\), but
  since \(g^{*}\) is injective we find \(\pi = 0\)---which can only be the case
  if \(\im g = C\), therefore \(g\) is surjective.

  We shall now show that \(\im f = \ker g\). Notice that since \(\im g^{*}
  \subseteq \ker f^{*}\) then \(f^{*} g^{*} = 0\) but then \((g f)^{*} = 0\)
  since \(\Hom_{\Mod{R}}(-, M)\) is contravariant. Therefore, if we take \(M
  \coloneq C\) and consider the element \(\Id_C \in \Hom_{\Mod{R}}(C, M)\), we
  obtain
  \[
  0 = (g f)^{*}(\Id_C) = \Id_C (g f) = g f,
  \]
  therefore \(\im f \subseteq \ker g\).

  For the other side of the inclusion, consider the module
  \(M \coloneq B/{\im f}\) and let \(p: B \to M\), then  denote the natural
  projection morphism---so that \(f^{*}(p) = p f = 0\). Since the sequence of
  abelian groups is exact, there must exist \(h \in \Hom_{\Mod{R}}(C, M)\) such
  that \(g^{*}(h) = h g = p\). If, for the sake of contradiction, \(\ker g\) is
  \emph{not} contained in \(\im f\), there must exist \(b \in B\) such that
  \(g(b) = 0\) but \(b \notin \im f\). This however implies that \(p(b) \neq
  0\), while \(h g(b) = p(b)\)---and since \(g(b) = 0\) then \(h g (b) = 0\),
  which is a contradiction. This shows that \(\ker g \subseteq \im f\).
\end{enumerate}
\end{proof}

\section{Bimodules}

\begin{definition}[Bimodule]
\label{def:bimodule}
Let \(R\) and \(S\) be any two rings, and \(M\) be an abelian group. We say that
\(M\) is a \emph{\((R, S)\)-bimodule} if \(M\) is both a left-\(R\)-module and a
right-\(S\)-module, and \(M\) must satisfy the associative law:
\[
r (m s) = (r m) s,
\]
for all \(r \in R\), \(m \in M\), and \(s \in S\).
\end{definition}

\begin{example}
\label{exp:R-commutative-R-R-bimodule}
Let \(R\) be a commutative ring and \(M\) be an \(R\)-module, then we can define
the structure of \((R, R)\)-bimodule on \(M\) by making the identification \(r m
= m r\) for any \(r \in R\) and \(M\). Such identification respects the module
structure since, given any other \(r' \in R\) one has
\[
(r r') m = r (r' m) = r' m r = (m r) r' = m (r r') = m (r' r).
\]
\end{example}

\begin{proposition}
\label{prop:hom-functor-and-bimodules}
Let \(R\) and \(S\) be rings, and \(M\) be a \emph{\((R, S)\)-bimodule}. The
following properties concern the relations between functors \(\Hom(M, -)\) and
\(\Hom(-, M)\), and bimodules:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item For any \emph{left-\(R\)-module} \(B\) we have that
  \(\Hom_{\lMod{R}}(M, B)\) is a \emph{left-\(S\)-module} with a product
  \(s \cdot f: M \to B\) mapping \(m \mapsto f(m s)\) for any
  \(f \in \Hom_{\lMod{R}}(M, B)\) and \(s \in S\). This can be summarized by the
  fact that
  \[
  \Hom_{\lMod{R}}(M, -): \lMod{R} \longrightarrow \lMod{S}
  \]
  is a covariant functor.

\item For any \emph{right-\(S\)-module} \(B\) we have that
  \(\Hom_{\rMod{S}}(M, B)\) is a \emph{right-\(R\)-module} with a product
  \(f \cdot r: M \to B\) mapping \(m \mapsto f(r m)\) for any
  \(f \in \Hom_{\rMod{S}}(M, B)\) and \(s \in S\). This can be summarized by the
  fact that
  \[
  \Hom_{\rMod{S}}(M, -): \rMod{S} \longrightarrow \rMod{R}
  \]
  is a covariant functor.

\item For any \emph{right-\(S\)-module} \(A\) we have that \(\Hom_{\rMod{S}}(A,
  M)\) is a \emph{left-\(R\)-module} with a product \(r \cdot f: A \to M\)
  mapping \(m \mapsto r f(m)\). This is summarized by the fact that
  \[
  \Hom_{\rMod{S}}(-, M): \rMod{S}^{\op} \longrightarrow \lMod{R}
  \]
  is a contravariant functor.

\item For any \emph{left-\(R\)-module} \(A\) we have that \(\Hom_{\lMod{R}}(A,
  M)\) is a \emph{right-\(S\)-module} with a product \(f \cdot s: A \to M\)
  mapping \(m \mapsto f(m) s\). This is summarized by the fact that
  \[
  \Hom_{\lMod{R}}(-, M): \lMod{R}^{\op} \longrightarrow \rMod{S}
  \]
  is a contravariant functor.
\end{enumerate}
\end{proposition}

\begin{proof}
The proof of the above statements are rather repetitive, but we shall lay all of
them down:
\begin{enumerate}[(a)]\setlength\itemsep{0em}
\item Given a morphism \(f \in \Hom_{\lMod{R}}(M, B)\), elements \(s, s' \in S\)
  and any \(m \in M\), one has
  \[
  ((s s') \cdot f)(m)
  = f(m (s s'))
  = f((m s) s')
  = (s' \cdot f)(m s)
  = (s \cdot (s' \cdot f))(m),
  \]
  therefore \((s s') \cdot f = s \cdot (s' \cdot f)\). This shows that
  \(\Hom_{\lMod{R}}(M, B)\) is a left-\(S\)-module. Now, if \(g: B \to C\) is
  any morphism of left-\(R\)-modules, consider the map
  \(g_*: \Hom_{\lMod{R}}(M, B) \to \Hom_{\lMod{R}}(M, C)\). Take a morphism
  \(f \in \Hom_{\lMod{R}}(M, B)\) and consider any two elements \(s \in S\) and
  \(m \in M\), then
  \[
  g_{*}(s f)(m) = g (s f)(m) = g f(m s) = s (g f(m)) = s g_{*}(f)(m),
  \]
  which shows that \(g_{*}\) is indeed a morphism between left-\(S\)-modules.

\item Let \(f \in \Hom_{\rMod{S}}(M, B)\), and \(r, r' \in R\) be any elements,
  then given any \(m \in M\) one has
  \[
  (f \cdot (r r'))(m)
  = f((r r') m)
  = f(r (r' m))
  = (f \cdot r) (r' m)
  = ((f \cdot r) \cdot r')(m).
  \]
  Therefore \(\Hom_{\rMod{S}}(M, B)\) has a structure of right-\(R\)-module. Let
  \(g: B \to C\) be any morphism of right-\(S\)-modules and consider its induced
  map \(g_{*}: \Hom_{\rMod{S}}(M, B) \to \Hom_{\rMod{S}}(M, C)\). If
  \(f \in \Hom_{\rMod{S}}(M, B)\) is any morphism, consider elements
  \(r \in R\) and \(m \in M\), then
  \[
  g_{*}((f \cdot r))(m)
  = g (f \cdot r)(m)
  = g f(r m)
  = r (g f(m))
  = r g_{*}(f)(m).
  \]
  Therefore \(g_{*}\) is a morphism between right-\(R\)-modules.

\item Let \(f \in \Hom_{\rMod{S}}(A, M)\) be any morphism, and consider two
  elements \(r, r' \in R\). From the product definition we obtain, for any
  \(m \in M\):
  \[
  ((r r') \cdot f)(m) = (r r') f(m) = r (r' f(m)) = r (r' \cdot f)(m)
  = (r \cdot (r' \cdot f))(m),
  \]
  which shows that \(\Hom_{\rMod{S}}(A, M)\) has a structure of
  left-\(R\)-module. For the second part of the proposition, consider a morphism
  \(g: A \to B\) between right-\(S\)-modules, and its corresponding map
  \(g^{*}: \Hom_{\rMod{S}}(B, M) \to \Hom_{\rMod{S}}(A, M)\). Let \(f \in
  \Hom_{\rMod{S}}(B, M)\), \(r \in R\), and \(b \in B\) be any elements, then
  one has
  \[
  g^{*}(r \cdot f)(m)
  = (r \cdot f) \circ g(m)
  = r f(g(m))
  = r g^{*}(f)(m).
  \]
  Therefore \(g^{*}\) is a morphism between left-\(R\)-modules.

\item Let \(f \in \Hom_{\lMod{R}}(A, M)\) be any morphism and take elements \(s,
  s' \in S\), then for any \(m \in M\) we have
  \[
  (f \cdot (s s'))(m) = f(m)(s s') = (f(m) s) s'
  = (f \cdot s)(m) s'
  = ((f \cdot s) \cdot s')(m),
  \]
  therefore \(\Hom_{\lMod{R}}(A, M)\) has the structure of a
  right-\(S\)-module. For the last part, take any morphism \(g: A \to B\) of
  left-\(R\)-modules and consider the induced map \(g^{*}: \Hom_{\lMod{R}}(B, M)
  \to \Hom_{\lMod{R}}(A, M)\). If \(f \in \Hom_{\lMod{R}}(B, M)\), \(s \in S\),
  and \(b \in B\) are any elements, then one has
  \[
  g^{*}(f \cdot s)(m) = (f \cdot s) \circ g(m)
  = f g(m) s
  g^{*}(f)(m) s.
  \]
  This shows that \(g^{*}\) is a morphism between right-\(S\)-modules.
\end{enumerate}
\end{proof}

\begin{example}
\label{exp:R-commutative-hom-functors}
If \(R\) is a commutative ring, and \(A\) and \(B\) are \(R\)-modules, then both
modules also have the structure of \((R, R)\)-bimodules (see
\cref{exp:R-commutative-R-R-bimodule}). From
\cref{prop:hom-functor-and-bimodules} we find that
\begin{align*}
\Hom_{\Mod{(R, R)}}(A, -):& \Mod{(R, R)} \longrightarrow \Mod{(R, R)}, \\
\Hom_{\Mod{(R, R)}}(-, B):& \Mod{(R, R)}^{\op} \longrightarrow \Mod{(R, R)}
\end{align*}
are the \(\Hom\) functors.
\end{example}

\begin{corollary}
\label{cor:Mor(R-M)-iso-M}
Let \(R\) be a ring and \(M\) be a left-\(R\)-module. Then
\(\Hom_{\lMod{R}}(R, M)\) is a left-\(R\)-module and there exists a natural
isomorphism of left-\(R\)-modules
\[
\Hom_{\lMod{R}}(R, M) \iso M,
\]
mapping \(f \mapsto f(1)\).
\end{corollary}

\begin{proof}
Since \(R\) has a natural structure of \((R, R)\)-bimodule, by means of item (a)
of \cref{prop:hom-functor-and-bimodules} we obtain that
\(\Hom_{\lMod{R}}(R, M)\) has a structure of left-\(R\)-module via the product
\(r \cdot f \in \Hom_{\lMod{R}}(R, M)\) mapping \(a \mapsto f(a r)\)---where
\(r \in R\) and \(f \in \Hom_{\lMod{R}}(R, M)\) are any two elements.

We first shows that the map \(\phi: \Hom_{\lMod{R}}(R, M) \to M\) given by
\(f \mapsto f(1)\) is a morphism of left-\(R\)-modules. Let
\(f, g \in \Hom_{\lMod{R}}(R, M)\) be any two elements, then
\(\phi(f + g) = (f + g)(1) = f(1) + g(1) = \phi(f) + \phi(g)\). Moreover, if
\(r \in R\) then
\[
\phi(r \cdot f) = (r \cdot f)(1) = f(1 \cdot r)
= f(r) = f(r \cdot 1) = r f(1) = r \phi(f).
\]
Therefore \(\phi\) is indeed a morphism as wanted. For injectivity it is simple
to realize that \(\phi(f) = f(1) = 0\) if and only if \(f = 0\), since
\(f(r) = f(r \cdot 1) = r f(1)\)---therefore \(\ker \phi = 0\). Moreover, given
any \(m \in M\), there exists a morphism \(g: R \to M\) uniquely determined by
\(g(1) \coloneq m\), so that \(\phi(g) = m\).
\end{proof}

\begin{theorem}
\label{thm:iso-prod-bimodules-morphism-set}
Let \(R\) and \(S\) be any two rings, and \(M\) be an \((R, S)\)-bimodule. Then
for any collection \((B_j)_{j \in J}\) of left-\(R\)-modules, the natural
isomorphism of abelian groups
\[
\Hom_{\lMod{R}}\big(A, \prod_{j \in J} B_j\big)
\iso
\prod_{j \in J} \Hom_{\lMod{R}}(A, B_j)
\]
is also an \emph{isomorphism of left-\(S\)-modules}.
\end{theorem}

\begin{proof}
Define \(B \coloneq \prod_{j \in J} B_j\), and name the isomorphism by
\(\phi\)---which maps \(f \mapsto (\pi_j f)_{j \in J}\), where \(\pi_j\) is the
\(j\)-th canonical projection. Notice that, given any morphism \(f \in
\Hom_{\lMod{R}}(A, B)\), \(s \in S\) and \(a \in A\), we have
\[
\pi_j \circ (s \cdot f)(a) = \pi_j(f(a s))
= \pi_j f(a s) = (s \cdot (\pi_j f))(a)
\]
for any \(j \in J\). Therefore, we conclude that
\[
\phi(s \cdot f) = (\pi_j(s \cdot f))_{j \in J} = (s \cdot (\pi_j f))_{j \in J}
= s (\pi_j f)_{j \in J} = s \phi(f),
\]
which proves that \(\phi\) is a morphism of left-\(S\)-modules. Since \(\phi\)
is also an isomorphism of abelian groups, then \(\phi\) is bijective, thus
\(\phi\) is indeed an isomorphism of left-\(S\)-modules.
\end{proof}

\begin{definition}[Dual module]
\label{def:dual-module}
Let \(M\) be a right-\(R\)-module (or left). We define
the \emph{dual module} of \(M\) to be the \emph{left-\(R\)-module}
(or right):
\[
M^{*} \coloneq \Hom_{\rMod{R}}(M, R).
\]
\end{definition}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../deep-dive"
%%% End:
